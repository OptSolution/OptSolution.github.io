<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[KinectFusion算法解读]]></title>
    <url>%2Farchives%2F14518.html</url>
    <content type="text"><![CDATA[R. A. Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking∗,” p. 10. KinectFusion就不需要多废话介绍了吧 算法结构 曲面测量：预处理过程，由原始的深度测量生成稠密的顶点和法线金字塔 曲面重建更新：全局场景融合过程，通过跟踪新的一帧深度数据得到的位姿，将曲面测累加到场景model中，由TSDF表示 曲面预期：并不是使用帧到帧的位姿估计，是使用帧到model的位姿估计。通过将符号距离函数raycasting到估计帧中来提供一个稠密曲面预期 传感器位姿估计：通过在当前帧和期望的曲面之间进行多尺度的ICP进行 曲面测量 在时刻kkk时获得一帧原始深度图Rk\mathbf{R}_kRk​，在图像域u∈U⊂R2\mathbf{u} \in \mathscr{U} \subset \mathbb{R}^2u∈U⊂R2中的每个像素u=(u,v)⊤\mathbf{u}=(u,v)^\topu=(u,v)⊤处都提供对应的已标定深度测量Rk(u)∈R\mathbf{R}_k(\mathbf{u}) \in \mathbb{R}Rk​(u)∈R。则有pk=Rk(u)K−1u˙\mathbf{p}_k = \mathbf{R}_k(\mathbf{u}) \mathbf{K}^{-1} \dot{\mathbf{u}}pk​=Rk​(u)K−1u˙为帧kkk的一个测量点。在原始深度图上进行双边滤波，以此得到降低噪声后的深度图Dk\mathbf{D}_kDk​， Dk(u)=1Wp∑q∈UNσs(∥u−q∥2)Nσr(∥Rk(u)−Rk(q)∥2)Rk(q)\mathbf{D}_k (\mathbf{u}) = \frac{1}{W_\mathbf{p}} \sum_{\mathbf{q} \in \mathscr{U}} \mathscr{N}_{\sigma_s} (\lVert \mathbf{u} - \mathbf{q} \rVert _2) \mathscr{N}_{\sigma_r} (\lVert \mathbf{R}_k(\mathbf{u}) - \mathbf{R}_k(\mathbf{q}) \rVert_2) \mathbf{R}_k(\mathbf{q}) Dk​(u)=Wp​1​q∈U∑​Nσs​​(∥u−q∥2​)Nσr​​(∥Rk​(u)−Rk​(q)∥2​)Rk​(q) 其中Nσ(t)=exp⁡(−t2σ−2)\mathscr{N}_{\sigma}(t) = \exp(-t^2\sigma^{-2})Nσ​(t)=exp(−t2σ−2)，WpW_{\mathbf{p}}Wp​是归一化常量。u˙\dot{\mathbf{u}}u˙表示齐次坐标，q=π(p)\mathbf{q} = \pi (\mathbf{p})q=π(p)表示透视投影p∈R3=(x,y,z)⊤,q∈R2=(x/z,y/z)⊤\mathbf{p} \in \mathbb{R}^3 = (x,y,z)^\top, \mathbf{q} \in \mathbb{R}^2 = (x/z, y/z)^\topp∈R3=(x,y,z)⊤,q∈R2=(x/z,y/z)⊤。 顶点和法线map 将滤波后的深度图反投影到传感器所在参考帧可以获得顶点map Vk\mathbf{V}_kVk​，公式(1) Vk(u)=Dk(u)K−1u˙\mathbf{V}_k (\mathbf{u}) = \mathbf{D}_k(\mathbf{u}) \mathbf{K}^{-1}\dot{\mathbf{u}} Vk​(u)=Dk​(u)K−1u˙ 在顶点map的领域中使用叉乘得到对应的法向量，公式(2) Nk(u)=v[(Vk(u+1,v)−Vk(u,v))×(Vk(u,v+1)−Vk(u,v))]\mathbf{N}_k (\mathbf{u}) = \mathbf{v} \lbrack (\mathbf{V}_k(u+1, v)-\mathbf{V}_k(u,v)) \times (\mathbf{V}_k(u,v+1) - \mathbf{V}_k(u,v)) \rbrack Nk​(u)=v[(Vk​(u+1,v)−Vk​(u,v))×(Vk​(u,v+1)−Vk​(u,v))] 其中v[x]=x/∥x∥2\mathbf{v} \lbrack \mathbf{x} \rbrack = \mathbf{x} / \lVert \mathbf{x} \rVert _2v[x]=x/∥x∥2​。同时定义了顶点有效性mask：对于每一个深度测量能转换为有效顶点的像素Mk(u)↦1\mathbf{M}_k(\mathbf{u}) \mapsto 1Mk​(u)↦1，反之如果深度测量值丢失的话Mk(u)↦0\mathbf{M}_k(\mathbf{u}) \mapsto 0Mk​(u)↦0。 曲面金字塔 计算由顶点和法线map金字塔表示的L=3L=3L=3多尺度曲面测量。首先计算深度图金字塔Dl∈[1…L]\mathbf{D}^{l \in [1 \dots L]}Dl∈[1…L]。设底层的深度图为原始的双边滤波后深度图，下采样版本Dl+1\mathbf{D}^{l+1}Dl+1从Dl\mathbf{D}^lDl通过块平均下采样到一半分辨率。深度值使用平均值，仅当和中心像素的值在3σr3\sigma_r3σr​之内时，保证平滑不会跨越深度边界。 顶点和法线map金字塔的每一层Vl∈[1…L],Nl∈[1…L]\mathbf{V}^{l \in [1 \dots L]}, \mathbf{N}^{l \in [1 \dots L]}Vl∈[1…L],Nl∈[1…L]使用该层的深度图和公式(1)(2)进行计算。将给定的相机到全局坐标系的仿射变换矩阵Tg,k\mathrm{T}_{g,k}Tg,k​使用在曲面测量上，可以得到全局顶点为Vkg(u)=Tg,kV˙k(u)\mathbf{V}^g_k(\mathbf{u}) = \mathrm{T}_{g,k} \dot{\mathbf{V}}_k(\mathbf{u})Vkg​(u)=Tg,k​V˙k​(u)，映射到全局中的法线为Nkg(u)=Rg,kNk(u)\mathbf{N}^g_k(\mathbf{u}) = \mathrm{R}_{g,k} \mathbf{N}_k(\mathbf{u})Nkg​(u)=Rg,k​Nk​(u)，其中 Tg,k=[Rg,ktg,k0⊤1]∈SE3\mathrm{T}_{g,k} = \begin{bmatrix} \mathrm{R}_{g,k} & \mathbf{t}_{g,k} \\ \mathbf{0}^\top & 1 \end{bmatrix} \in \mathbb{SE}_3 Tg,k​=[Rg,k​0⊤​tg,k​1​]∈SE3​ TSDF 每一个连续的深度帧，使用其对应的相机位姿，增量式融合到一个用TSDF表示的单一3D重建中。将融合了配准后帧1…k1 \dots k1…k深度测量值的TSDF表示为Sk(p)\mathbf{S}_k(\mathbf{p})Sk​(p)，其中p∈R3\mathbf{p} \in \mathbb{R}^3p∈R3是将被重建的3D volume中全局帧的点。TSDF点每个位置都要保存两个元素：当前的截断符号距离值Fk(p)\mathbf{F}_k(\mathbf{p})Fk​(p)和权重Wk(p)\mathbf{W}_k(\mathbf{p})Wk​(p)， Sk(p)↦[Fk(p),Wk(p)]\mathbf{S}_k(\mathbf{p}) \mapsto \lbrack \mathbf{F}_k(\mathbf{p}) , \mathbf{W}_k(\mathbf{p}) \rbrack Sk​(p)↦[Fk​(p),Wk​(p)] 截断 稠密的曲面测量在曲面重建中提供了两个重要约束。首先，假设可以截断深度测量的不确定性，比如真值在测量值的±μ\pm \mu±μ之间。那么对于从相机中心沿着深度图射线的距离rrr来说，r(λRk​(u)+μ)的范围内无法获取曲面信息。因此仅仅需要表达曲面测量在∣r−λRk(u)∣≤μ| r - \lambda \mathbf{R}_k (\mathbf{u}) | \leq \mu∣r−λRk​(u)∣≤μ范围内的不确定性的区域。可见空间的点到曲面上最近点的距离大于μ\muμ时被截断为最大距离μ\muμ，不可见的点距离超过μ\muμ时不被测量。符号距离函数表达了到曲面最近点的距离。 投影截断符号距离函数 对于一个已知位姿Tg,k\mathrm{T}_{g,k}Tg,k​的原始深度图Rk\mathbf{R}_kRk​，在全局帧中点p\mathbf{p}p处的投影TSDF[FRk,WRk][\mathbf{F}_{\mathbf{R}_k}, \mathbf{W}_{\mathbf{R}_k}][FRk​​,WRk​​]为 FRk(p)=Ψ(λ−1∥tg,k−p∥2−Rk(x))λ=∥K−1x˙∥2x=⌊π(KTg,k−1p)⌋Ψ(η)={min⁡(1,ημ)sgn(η)iff η≥−μnullotherwise\begin{aligned} \mathbf{F}_{\mathbf{R}_k}(\mathbf{p}) &= \Psi \left( \lambda^{-1} \lVert \mathbf{t}_{g,k} - \mathbf{p} \rVert_2 - \mathbf{R}_k(\mathbf{x}) \right) \\ \lambda &= \lVert \mathbf{K}^{-1} \dot{\mathbf{x}} \rVert_2 \\ \mathbf{x} &= \lfloor \pi \left( \mathbf{K} \mathrm{T}_{g,k}^{-1} \mathbf{p} \right) \rfloor \\ \Psi (\eta) &= \begin{cases} \min (1, \frac{\eta}{\mu}) \text{sgn}(\eta) &\text{iff } \eta \geq -\mu \\ null & otherwise \end{cases} \end{aligned} FRk​​(p)λxΨ(η)​=Ψ(λ−1∥tg,k​−p∥2​−Rk​(x))=∥K−1x˙∥2​=⌊π(KTg,k−1​p)⌋={min(1,μη​)sgn(η)null​iff η≥−μotherwise​​ ⌊⋅⌋\lfloor \cdot \rfloor⌊⋅⌋为最近邻查找，而不使用深度值内插。λ\lambdaλ为到归一化平面上的距离。Ψ\PsiΨ进行截断。tg,k\mathbf{t}_{g,k}tg,k​为当前相机坐标，∥tg,k−p∥2\lVert \mathbf{t}_{g,k}-\mathbf{p} \rVert_2∥tg,k​−p∥2​为点在当前坐标系中的坐标。相关推导可以结合公式(1)进行。 相关权重WRk(p)\mathbf{W}_{\mathbf{R}_k} (\mathbf{p})WRk​​(p)与cos⁡(θ)/Rk(x)\cos (\theta) / \mathbf{R}_k (\mathbf{x})cos(θ)/Rk​(x)成比例，θ\thetaθ是局部帧中像素射线方向和曲面法线方向的夹角。 投影TSDF仅仅在FRk(p)=0\mathbf{F}_{\mathbf{R}_k}(\mathbf{p}) = 0FRk​​(p)=0或者仅仅存在孤立的点(之前在此处没有测量值)时恰好有效。 融合 所有深度图的全局融合是通过将每个深度图分别计算得到的所有独立TSDF进行加权平均，可以被看作由多个噪声的TSDF测量进行去噪得到全局的TSDF。在L2\mathscr{L}_2L2​范数下的去噪(融合)曲面结果为作为000交界的逐点符号距离函数F最小化： min⁡F∈F∑k∥WRkFRk−F∥2\min_{\mathrm{F} \in \mathscr{F}} \sum_k \lVert \mathbf{W}_{\mathbf{R}_k} \mathbf{F}_{\mathbf{R}_k} - \mathrm{F} \rVert _2 F∈Fmin​k∑​∥WRk​​FRk​​−F∥2​ 这个解可以由更多数据项使用简单的加权平均增量获得，在每个点{p∣FRk(p)≠null}\{ \mathbf{p} | \mathbf{F}_{\mathbf{R}_k}(\mathbf{p}) \neq null \}{p∣FRk​​(p)≠null}处定义： Fk(p)=Wk−1(p)Fk−1(p)+WRk(p)FRk(p)Wk−1(p)+WRk(p)Wk(p)=Wk−1(p)+WRk(p)\begin{aligned} \mathbf{F}_k(\mathbf{p}) &= \frac{\mathbf{W}_{k-1}(\mathbf{p}) \mathbf{F}_{k-1}(\mathbf{p}) + \mathbf{W}_{\mathbf{R}_k}(\mathbf{p}) \mathbf{F}_{\mathbf{R}_k}(\mathbf{p})}{\mathbf{W}_{k-1}(\mathbf{p}) + \mathbf{W}_{\mathbf{R}_k}(\mathbf{p})} \\ \mathbf{W}_{k}(\mathbf{p}) &= \mathbf{W}_{k-1}(\mathbf{p}) + \mathbf{W}_{\mathbf{R}_k}(\mathbf{p}) \end{aligned} Fk​(p)Wk​(p)​=Wk−1​(p)+WRk​​(p)Wk−1​(p)Fk−1​(p)+WRk​​(p)FRk​​(p)​=Wk−1​(p)+WRk​​(p)​ 实践中发现，权重WRk(p)=1\mathbf{W}_{\mathbf{R}_k}(\mathbf{p}) = 1WRk​​(p)=1时也能提供很好的结果。并且，将更新后超过某个值Wη\mathbf{W}_\etaWη​的权重截断 Wk(p)←min⁡(Wk−1(p)+WRk(p),Wη)\mathbf{W}_{k}(\mathbf{p}) \leftarrow \min (\mathbf{W}_{k-1}(\mathbf{p}) + \mathbf{W}_{\mathbf{R}_k}(\mathbf{p}) , \mathbf{W}_\eta) Wk​(p)←min(Wk−1​(p)+WRk​​(p),Wη​) 在有动态目标运动的场景中，可以获得运动的平均曲面重建结果。 原始的深度测量值被用来进行TSDF融合，双边滤波的版本被用在跟踪中。 滤波后移除了高频部分，类似噪声的部分丢失会导致重建更好结果的能力下降，因为细节很多都在高频的部分。 对TSDF进行raycasting得到期望曲面 计算一个稠密点期望曲面，通过将零水平集Fk=0\mathbf{F}_k = 0Fk​=0渲染到当前位姿Tg,k\mathrm{T}_{g,k}Tg,k​的虚拟相机中。期望曲面储存为(这是重要的，估计位姿的数据关联就是将这些顶点投影到下一帧中)参考帧kkk中顶点和法线map V^k\hat{\mathbf{V}}_kV^k​和N^k\hat{\mathbf{N}}_kN^k​，并用于相机位姿估计。 当有了全局SDF形式表示的稠密曲面重建之后，便可以对每个像素进行raycast。从像素最小的深度开始，沿着像素对应的射线Tg,kK−1u˙\mathrm{T}_{g,k}\mathbf{K}^{-1}\dot{\mathbf{u}}Tg,k​K−1u˙，直到零交界处(可视曲面的+ve+ve+ve到−ve-ve−ve范围)。当到达−ve-ve−ve到+ve+ve+ve范围的背面或者存在正在工作的volume时同样也停止，这两种情况将会导致像素u\mathbf{u}u处没有曲面测量值。 在曲面界面Fk(p)=0\mathbf{F}_k(\mathbf{p}) = 0Fk​(p)=0上或者离其非常近的点，TSDF点梯度在该处被假设为正交于零水平集，所以与像素u\mathbf{u}u相关点p\mathbf{p}p处的曲面法线可以从Fk\mathbf{F}_kFk​直接用SDF的数值导数计算： Rg,kN^k=N^kg(u)=v[∇F(p)]∇F=[∂F∂x,∂F∂y,∂F∂z]⊤\begin{aligned} \mathrm{R}_{g,k} \hat{\mathbf{N}}_k &= \hat{\mathbf{N}}^g_k (\mathbf{u}) = \mathbf{v} [\nabla \mathbf{F}(\mathbf{p})] \\ \nabla \mathbf{F} &= \lbrack \frac{\partial \mathbf{F}}{\partial x} , \frac{\partial \mathbf{F}}{\partial y}, \frac{\partial \mathbf{F}}{\partial z} \rbrack ^\top \end{aligned} Rg,k​N^k​∇F​=N^kg​(u)=v[∇F(p)]=[∂x∂F​,∂y∂F​,∂z∂F​]⊤​ 相关原理可以参考原文的参考文献[4]，就是算当前帧的像素对应更新后曲面上的哪个点。 相机位姿估计 实时相机定位包含对每一帧新的深度图估计当前相机位姿Tg,k∈SE3\mathrm{T}_{g,k} \in \mathbb{SE}_3Tg,k​∈SE3​。在这个工作中，使用两个因素带来的优势，使用深度图中所有的数据进行一个基于稠密ICP的位姿估计。首先，由于很高的跟踪帧率，可认为相邻两帧之间的运动非常小。其次，现代GPU硬件可以实现高度并行化计算。该系统中通过align实时曲面测量(Vk,Nk)(\mathbf{V}_k, \mathbf{N}_k)(Vk​,Nk​)到由前一帧得到的(V^k−1,N^k−1)(\hat{\mathbf{V}}_{k-1}, \hat{\mathbf{N}}_{k-1})(V^k−1​,N^k−1​)模型预期。 利用期望曲面，估计相机位姿Tg,k\mathrm{T}_{g,k}Tg,k​的全局点面能量函数为 E(Tg,k)=∑u∈UΩk(u)≠null∥(Tg,kV˙k(u)−V^k−1g(u^))⊤N^k−1g(u^)∥2\mathbf{E}(\mathrm{T}_{g,k}) = \sum_{ \begin{aligned} \mathbf{u} &\in \mathscr{U} \\ {\Omega}_k(\mathbf{u}) &\neq null \end{aligned}} \lVert \left( \mathrm{T}_{g,k} \dot{\mathbf{V}}_k(\mathbf{u}) - \hat{\mathbf{V}}^g_{k-1}(\hat{\mathbf{u}}) \right)^\top \hat{\mathbf{N}}^g_{k-1}(\hat{\mathbf{u}}) \rVert_2 E(Tg,k​)=uΩk​(u)​∈U≠null​∑​∥(Tg,k​V˙k​(u)−V^k−1g​(u^))⊤N^k−1g​(u^)∥2​ 通过计算透视投影点，使用投影数据关联算法(就是将储存为期望曲面的顶点投影到该帧上)得到一系列顶点对应{Vk(u),V^k−1(u^)∣Ω(u)≠null}\{ \mathbf{V}_k(\mathbf{u}), \hat{\mathbf{V}}_{k-1}(\mathbf{\hat{u}}) | \Omega(\mathbf{u}) \neq null \}{Vk​(u),V^k−1​(u^)∣Ω(u)≠null}。设定阈值处理特别不正确的对应 Ω(u)≠null iff{Mk(u)=1,and∥T~g,kzV˙k(u)−V^k−1g(u^)∥≤εd,and⟨R~g,kzNk(u),N^k−1g(u^)⟩≤εθ.\Omega(\mathbf{u}) \neq null \text{ iff} \begin{cases} \mathbf{M}_k(\mathbf{u}) &= &1 ,&\text{and}\\ \lVert \tilde{\mathrm{T}}^z_{g,k} \dot{\mathbf{V}}_k(\mathbf{u}) - \hat{\mathbf{V}}^g_{k-1}(\hat{\mathbf{u}}) \rVert &\leq &\varepsilon_d ,& \text{and} \\ \langle \tilde{R}^z_{g,k} \mathbf{N}_k(\mathbf{u}), \hat{\mathbf{N}}^g_{k-1}(\mathbf{\hat{u}}) \rangle &\leq &\varepsilon_\theta .& \end{cases} Ω(u)≠null iff⎩⎪⎨⎪⎧​Mk​(u)∥T~g,kz​V˙k​(u)−V^k−1g​(u^)∥⟨R~g,kz​Nk​(u),N^k−1g​(u^)⟩​=≤≤​1,εd​,εθ​.​andand​ T~g,kz=0\tilde{\mathrm{T}}^{z=0}_{g,k}T~g,kz=0​由前一帧的位姿Tg,k\mathrm{T}_{g,k}Tg,k​初始化。]]></content>
      <tags>
        <tag>3D Reconstruct</tag>
        <tag>TSDF</tag>
        <tag>KinectFusion</tag>
        <tag>RGBD</tag>
        <tag>kinfu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TSDF]]></title>
    <url>%2Farchives%2F49472.html</url>
    <content type="text"><![CDATA[B. Curless and M. Levoy, “A volumetric method for building complex models from range images,” 1996, pp. 303–312. 一个将align后的range image融合的方法，使用累积权重的符号距离函数。 文中算法性质： 不确定性的表示，误差分布是不对称的，其主方向为视线方向 使用所有的range数据 增量式和有序的独立更新 时间和空间有效性 鲁棒性 没有拓扑形式的限制 重建中填满空间的能力 体素融合 算法使用了一个连续隐函数D(x)D(\mathbf{x})D(x)，通过采样表示。这个函数是每个点沿着视线方向到最近的range曲面距离的加权和。 融合规则 通过将从range图像1,…,n1, \dots, n1,…,n中获取的符号距离函数d1(x),d2(x),…,dn(x)d_1(\mathbf{x}), d_2(\mathbf{x}), \dots, d_n(\mathbf{x})d1​(x),d2​(x),…,dn​(x)和权重函数w1(x),w2(x),…,wn(x)w_1(\mathbf{x}), w_2(\mathbf{x}), \dots, w_n(\mathbf{x})w1​(x),w2​(x),…,wn​(x)结合来构造这个函数。该方法的结合规则对每个体素给出一个累积符号距离函数D(x)D(\mathbf{x})D(x)和一个累计权重W(x)W(\mathbf{x})W(x)。在离散的体素栅格上表示这些函数并且检测出一个D(x)=0D(\mathbf{x}) =0D(x)=0的等值面。对于不同的range scanning技术，权重的选择是不同的。比如光线三角扫描器(optical triangulation scanners)，权重取决于每一个顶点(vertex)法线和视线方向的点积，当视线和切平面夹角越小的时候不确定度越高。mesh边界上的数据具有更高的不确定性，需要更小的权重。结合规则为： D(x)=∑wi(x)di(x)∑wi(x)W(x)=∑wi(x)\begin{aligned} D(\mathbf{x}) &= \frac{\sum w_i(\mathbf{x}) d_i(\mathbf{x})}{\sum w_i(\mathbf{x})} \\ W(\mathbf{x}) &= \sum w_i(\mathbf{\mathbf{x}}) \end{aligned} D(x)W(x)​=∑wi​(x)∑wi​(x)di​(x)​=∑wi​(x)​ 其中di(x)d_i(\mathbf{x})di​(x)和wi(x)w_i(\mathbf{x})wi​(x)分别是从range image中得到的符号距离函数和权重函数。为了写成增量式计算： Di+1(x)=Wi(x)Di(x)+wi+1(x)di+1(x)Wi(x)+wi+1(x)Wi+1(x)=Wi(x)+wi+1(x)\begin{aligned} D_{i+1}(\mathbf{x}) &= \frac{W_i(\mathbf{x}) D_i(\mathbf{x}) + w_{i+1}(\mathbf{x}) d_{i+1}(\mathbf{x})}{W_i(\mathbf{x}) + w_{i+1}(\mathbf{x})} \\ W_{i+1}(\mathbf{x}) &= W_i(\mathbf{x}) + w_{i+1}(\mathbf{x}) \end{aligned} Di+1​(x)Wi+1​(x)​=Wi​(x)+wi+1​(x)Wi​(x)Di​(x)+wi+1​(x)di+1​(x)​=Wi​(x)+wi+1​(x)​ 其中Di(x)D_i(\mathbf{x})Di​(x)和Wi(x)W_i(\mathbf{x})Wi​(x)是融合第iii帧range image后的累积符号距离函数和权重函数。 截断距离 原则上，距离函数和权重函数都可以无限延长。但是为了保护目标对面的曲面不受影响，该方法减少曲面背后的权重函数。此时需要考虑在哪里减少权重函数。需要保持在曲面背后足够远以保证所有的数据(distance ramp)对零交界面有所贡献，同时也应该足够窄以保证曲面的其它地方不受影响。为了满足这个需求，该方法在距离等于测量的最大不确定间隔的一半时将权重骤减/截断。同样的，曲面前面也不需要扩展太远。 在二维和三维空间中，range测量对应带着权重函数的曲线和曲面，同时signed distance ramps有和传感器不确定性主方向相同的方向。实际上，该方法使用一个固定的点表示符号距离函数，其边界在DminD_{min}Dmin​和DmaxD_{max}Dmax​之间。DminD_{min}Dmin​和DmaxD_{max}Dmax​必须一个为负数，一个为正数。 算法流程 首先将所有体素权重设为000，因此新的数据可以覆写初始栅格值。然后通过从采样格(sampled lattice)的最近邻构造三角形来网格化range image。通过丢弃长度超过阈值的边来保证网格化没有横跨不连续的地方。必须对以上提及的每一个顶点计算一个对应的权重。一旦range image转换为了每个顶点带权重的三角mesh，就可以开始更新体素栅格了。 符号距离贡献通过从传感器投射一条射线穿过曲面周围的每一个体素，然后在三角网格mesh上与曲面相交来计算(每个点到曲面的距离)。权重通过相交的三角形顶点权重的线性内插得到。 空洞填补 以上内容描述的算法被设计重建曲面的客观部分，不可见部分将显示为空洞。 算法的关键是将volume中所有的点分为三个状态：不可见、空或者近曲面。曲面前面的部分被看作空D(x)=Dmin,W(x)=0D(\mathbf{x})=D_{min},W(\mathbf{x})=0D(x)=Dmin​,W(x)=0，近曲面区域包含000等值面Dmin]]></content>
      <tags>
        <tag>3D Reconstruct</tag>
        <tag>TSDF</tag>
        <tag>KinectFusion</tag>
        <tag>DynamicFusion</tag>
        <tag>mesh</tag>
        <tag>voxel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用于曲面配准的非刚体ICP算法最优化步骤]]></title>
    <url>%2Farchives%2F46063.html</url>
    <content type="text"><![CDATA[B. Amberg, S. Romdhani, and T. Vetter, “Optimal Step Nonrigid ICP Algorithms for Surface Registration,” in 2007 IEEE Conference on Computer Vision and Pattern Recognition, Minneapolis, MN, USA, 2007, pp. 1–8. Overview 配准是将template warp到target上。该算法使用局部仿射性进行正则化，假设每个顶点都对应一个仿射变换，并且最小化相邻顶点对应仿射变换的差(局部平滑)。由于一对匹配点无法计算得到一个仿射变换，因此引入正则项作为新的约束。 该文章定义了非刚体ICP框架的最优化步骤，扩展的ICP方法适用于非刚体形变并且保留了ICP原本的收敛性。 构造CostFunction 给定template mesh为S=(V,E)\mathcal{S} = \left( \mathcal{V}, \mathcal{E} \right)S=(V,E)拥有nnn个顶点V\mathcal{V}V和mmm条边E\mathcal{E}E的图。Target T\mathcal{T}T为任意一种中3D空间中可以给其中任意一个点找到最近点的表示。 需要求解的数据是每个template顶点对应的仿射变换矩阵Xi\bm{X}_iXi​，完整的形式为 X:=[X1…Xn]T\bm{X} \coloneqq \begin{bmatrix} \bm{X}_1 & \dots & \bm{X}_n \end{bmatrix} ^T X:=[X1​​…​Xn​​]T 距离项 形变后template上的顶点和target之间的距离应该很小，距离项由此构造为 Ed(X):=∑vi∈Vwidist2(T,Xivi)E_d(\bm{X}) \coloneqq \sum_{\bm{v}_i \in \mathcal{V}} w_i \text{dist}^2(\mathcal{T}, \bm{X}_i \bm{v}_i) Ed​(X):=vi​∈V∑​wi​dist2(T,Xi​vi​) vi\bm{v}_ivi​为其次向量[x,y,z,1]T\begin{bmatrix} x,y,z,1 \end{bmatrix}^T[x,y,z,1​]T，点v\bm{v}v和它在target中最近点的距离为dist(T,v)\text{dist}(\mathcal{T}, \bm{v})dist(T,v)。使用分层边界球方法提高最近点搜索的速度。匹配的可信度为权重wiw_iwi​，当某个点没有对应点时，其权重为000。 stiffness项 Stiffness项用来惩罚相邻顶点间仿射变换的不同。使用加权矩阵G:=diag(1,1,1,γ)\bm{G} \coloneqq \text{diag} (1,1,1,\gamma)G:=diag(1,1,1,γ)，得到 Es(X):=∑{i,j}∈E∥(Xi−Xj)G∥F2E_s(\bm{X}) \coloneqq \sum_{\{i,j\} \in \mathcal{E}} \lVert (\bm{X}_i - \bm{X}_j)\bm{G} \rVert ^2_F Es​(X):={i,j}∈E∑​∥(Xi​−Xj​)G∥F2​ landmark项 用来初始化和引导配准，对cost function本身影响不大。给定一系列landmark L={(vi1,l1),…,(vil,ll)}\mathcal{L} = \{ (\bm{v}_{i_1}, \bm{l}_1), \dots , (\bm{v}_{i_l}, \bm{l}_l) \}L={(vi1​​,l1​),…,(vil​​,ll​)}将template顶点映射到target顶点上， El(X):=∑{vi,l}∈L∥Xivi−l∥2E_l(\bm{X}) \coloneqq \sum_{\{\bm{v}_i, \bm{l}\} \in \mathcal{L}} \lVert \bm{X}_i \bm{v}_i - \bm{l} \rVert ^2 El​(X):={vi​,l}∈L∑​∥Xi​vi​−l∥2 完整的CostFunction E(X):=Ed(X)+αEs(X)+βEl(X)E(\bm{X}) \coloneqq E_d(\bm{X}) + \alpha E_s(\bm{X}) + \beta E_l(\bm{X}) E(X):=Ed​(X)+αEs​(X)+βEl​(X) 计算步骤 初始化X0\bm{X}^0X0 对每个stiffness αi∈{α1,…αn}\alpha ^i \in \{ \alpha ^1, \dots \alpha ^n \}αi∈{α1,…αn}都有αi>αi+1\alpha^i > \alpha^{i+1}αi>αi+1 到∥Xj−Xj−1∥]]></content>
      <tags>
        <tag>non-rigid</tag>
        <tag>ICP</tag>
        <tag>Registration</tag>
        <tag>3D Reconstruct</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DynamicFusion简要解析]]></title>
    <url>%2Farchives%2F4028.html</url>
    <content type="text"><![CDATA[DynamicFusion所做的工作：基于体素流场，将每帧场景状态变换到固定的（fixed, canonical）frame。 主要贡献：由刚体场景（KinectFusion）发展得到的，保留体素帧融合（volumetric scan fusion）最优特性的一个非刚体变换和融合的方法。 次要贡献：有效表达了体素warp，并实时计算。 Overview 算法有3个核心组成部分： 估算体素model-to-frame的warp场参数 利用计算得到的warp场，将实时深度图融合到canonical空间 调整warp场的结构去获取新的几何 稠密非刚体warp场 使用体素warp场表示动态场景运动，每一个点都对应一个6D的变换W:S↦SE(3)\mathcal{W}:\mathbf{S} \mapsto \mathbf{SE}(3)W:S↦SE(3)，每一个canonical点vc∈Sv_c \in \mathbf{S}vc​∈S，Tlc=W(vc)\mathbf{T}_{lc} = \mathcal{W}(v_c)Tlc​=W(vc​)将点从canonical空间变换到实时非刚体形变参考帧。如： (vt⊤,1)⊤=W(vc)(vc⊤,1)⊤(nt⊤,0)⊤=W(vc)(nc⊤,0)⊤\begin{aligned} \left( v_t^\top, 1 \right)^\top &= \mathcal{W}(v_c) \left( v_c^\top, 1 \right)^\top \\ \left( n_t^\top, 0 \right)^\top &= \mathcal{W}(v_c) \left( n_c^\top, 0 \right)^\top \end{aligned} (vt⊤​,1)⊤(nt⊤​,0)⊤​=W(vc​)(vc⊤​,1)⊤=W(vc​)(nc⊤​,0)⊤​ 对偶四元数内插 由于直接进行稠密计算不现实，计算量太大，warp场计算使用对偶四元数内插（DQB）方式进行，warp函数定义为： W(xc)≡SE3(DQB(xc))\mathcal{W}(x_c) \equiv SE3( \mathbf{DQB} (x_c) ) W(xc​)≡SE3(DQB(xc​)) 其中SE3(⋅)SE3(\cdot)SE3(⋅)将对偶四元数转换为SE(3)\mathbf{SE}(3)SE(3)变换矩阵， DQB(xc)≡∑k∈N(xc)wk(xc)q^kc∥∑k∈N(xc)wk(xc)q^kc∥\mathbf{DQB} (x_c) \equiv \frac{\sum_{k \in N(x_c)} \mathbf{w}_k(x_c)\mathbf{\hat{q}}_{kc}} {\lVert \sum_{k \in N(x_c)} \mathbf{w}_k(x_c)\mathbf{\hat{q}}_{kc} \rVert} DQB(xc​)≡∥∑k∈N(xc​)​wk​(xc​)q^​kc​∥∑k∈N(xc​)​wk​(xc​)q^​kc​​ q^kc∈R8\mathbf{\hat{q}}_{kc} \in \mathbb{R}^8q^​kc​∈R8为单位对偶四元数，N(x)N(x)N(x)为点xxx的kkk最近邻变换node，wk:R3↦R\mathbf{w}_k:\mathbb{R}^3 \mapsto \mathbb{R}wk​:R3↦R定义了决定每个node影响半径的权重。也就是点xxx的变换通过kkk最近邻node对应变换的单位对偶四元数加权和再归一化，得到对应的单位对偶四元数之后专为变换矩阵。 warp场状态表示 ttt时刻的warp场Wt\mathcal{W}_tWt​状态由nnn个形变node Nwarpt={dgv,dgw,dgse3}t\mathcal{N}^t_\mathbf{warp} = \{ \mathbf{dg}_v, \mathbf{dg}_w, \mathbf{dg}_{se3} \}_tNwarpt​={dgv​,dgw​,dgse3​}t​表示。对于每个node i=1…ni = 1 \dots ni=1…n而言，dgvi∈R3\mathbf{dg}_v^i \in \mathbb{R}^3dgvi​∈R3为canonical帧中坐标，dgw\mathbf{dg}_wdgw​为半径基权重（radial basis weight），控制warp场内插权重， wi(xc)=exp⁡(−∥dgvi−xc∥2/(2(dgwi)2))\mathbf{w}_i (x_c) = \exp \left(- \lVert \mathbf{dg}^i_v - x_c \rVert ^2 / \left( 2 \left( \mathbf{dg}^i_w \right)^2 \right) \right) wi​(xc​)=exp(−∥dgvi​−xc​∥2/(2(dgwi​)2)) Tic=dgse3i\mathbf{T}_{ic} = \mathbf{dg}^i_{se3}Tic​=dgse3i​为node对应的变换。 对于整个warp场而言，可以分离出由于相机运动等原因造成的公共刚体变换。最后完整的warp场函数为 Wt(xc)=TlwSE3(DQB(xc))\mathcal{W}_t(x_c) = \mathbf{T}_{lw} SE3( \mathbf{DQB} (x_c) ) Wt​(xc​)=Tlw​SE3(DQB(xc​)) 稠密的非刚体曲面融合 在得到model-to-frame的warp场Wt\mathcal{W}_tWt​之后，就要更新canonical模型几何了。 TSDF表示 在canonical空间S\mathbf{S}S中重建由采样TSDF V:S↦R2\mathbf{TSDF} \space \mathcal{V} : \mathsf{S} \mapsto \mathbb{R}^2TSDF V:S↦R2表示。S\mathsf{S}S在体素域中S⊂N3\mathsf{S} \subset \mathbb{N}^3S⊂N3，每个体素x∈S\mathbf{x} \in \mathsf{S}x∈S对应一个采样点xcx_cxc​。元组V(x)↦[v(x)∈R,w(x)∈R]⊤\mathcal{V}(x) \mapsto \lbrack \mathsf{v}(\mathbf{x}) \in \mathbb{R}, \mathsf{w}(\mathbf{x}) \in \mathbb{R} \rbrack ^\topV(x)↦[v(x)∈R,w(x)∈R]⊤，v(x)\mathsf{v}(\mathbf{x})v(x)为该店所有投影TSDF\mathbf{TSDF}TSDF值的加权平均，w(x)\mathsf{w}(\mathbf{x})w(x)为相关权重和。 TSDF融合 对于给定的实时深度图DtD_tDt​，将每个体素中心warp到实时帧中，(xt⊤,1)⊤=Wt(xc)(xc⊤,1)⊤\left( x_t^\top, 1 \right)^\top = \mathcal{W}_t(x_c) \left( x_c^\top, 1 \right)^\top(xt⊤​,1)⊤=Wt​(xc​)(xc⊤​,1)⊤，然后通过直接将warp之后的（体素）中心投影到该深度帧中进行TSDF\mathbf{TSDF}TSDF曲面融合操作。 psdf(xc)=[K−1Dt(uc)[uc⊤,1]⊤]z−[xt]z\mathbf{psdf} (x_c) = \lbrack \mathbf{K}^{-1} D_t(u_c) \lbrack u_c^\top, 1 \rbrack ^\top \rbrack _z - \lbrack x_t \rbrack _z psdf(xc​)=[K−1Dt​(uc​)[uc⊤​,1]⊤]z​−[xt​]z​ 其中uc=π(Kxt)u_c = \pi \left( \mathbf{K}x_t \right)uc​=π(Kxt​)为体素中心投影对应的像素，通过这种投影将体素和深度图像素对应起来。在实时帧坐标系下，计算使用深度图得到的zzz轴坐标和warp后对应体素中心的zzz轴坐标的差值。 然后就该更新TSDF\mathbf{TSDF}TSDF了， V(x)t={[v′(x),w′(x)]⊤,if psdf(dc(x))>−τV(x)t−1,otherwise\mathcal{V}(\mathbf{x})_t = \begin{cases} \lbrack \mathsf{v}'(\mathbf{x}), \mathsf{w}'(\mathbf{x}) \rbrack ^\top , &\text{if } \mathbf{psdf}(\mathbf{dc}(\mathbf{x})) > - \tau \\ \mathcal{V}(\mathbf{x})_{t-1} , &\text{otherwise} \end{cases} V(x)t​={[v′(x),w′(x)]⊤,V(x)t−1​,​if psdf(dc(x))>−τotherwise​ dc(⋅)\mathbf{dc}(\cdot)dc(⋅)将离散的体素转变到连续的TSDF\mathbf{TSDF}TSDF域中，截断距离τ>0\tau > 0τ>0， v′(x)=v(x)t−1w(x)t−1+min⁡(ρ,τ)w(x)w(x)t−1+w(x)ρ=psdf(dc(x))w′(x)=min⁡(w(x)t−1+w(x),wmax)w(x)∝1k∑i∈N(xc)∥dgwi−xc∥2\begin{aligned} \mathsf{v}'(\mathbf{x}) &= \frac{\mathsf{v}(\mathbf{x})_{t-1} \mathsf{w}(\mathbf{x})_{t-1} + \min (\rho, \tau) w(\mathbf{x})}{\mathsf{w}(\mathbf{x})_{t-1} + w(\mathbf{x})} \\ \rho &= \mathbf{psdf}(\mathbf{dc}(\mathbf{x})) \\ \mathsf{w}'(\mathbf{x}) &= \min (\mathsf{w}(\mathbf{x})_{t-1} + w(\mathbf{x}), w_{max}) \\ w(\mathbf{x}) &\propto \frac{1}{k} \sum _{i \in N(x_c)} \lVert \mathbf{dg}^i_w - x_c \rVert _2 \end{aligned} v′(x)ρw′(x)w(x)​=w(x)t−1​+w(x)v(x)t−1​w(x)t−1​+min(ρ,τ)w(x)​=psdf(dc(x))=min(w(x)t−1​+w(x),wmax​)∝k1​i∈N(xc​)∑​∥dgwi​−xc​∥2​​ 最后这个这个似乎不应该是dgwi\mathbf{dg}_w^idgwi​，而应该是dgvi\mathbf{dg}_v^idgvi​，因为后者才是表示3维坐标的量。 估计warp场状态Wt\mathcal{W}_tWt​ 前面说了Wt\mathcal{W}_tWt​的数据结构与如何在曲面融合中使用，但是还没有说如何计算得到，现在开始计算这个东西。 方法是使用给出的深度图DtD_tDt​和对应的重建V\mathcal{V}V，通过能量函数最小化估计当前变换dgse3\mathbf{dg}_{se3}dgse3​的值： E(Wt,V,Dt,E)=Data(Wt,V,Dt)+λReg(Wt,E)E(\mathcal{W}_t, \mathcal{V}, D_t, \mathcal{E}) = \mathbf{Data}(\mathcal{W}_t, \mathcal{V}, D_t) + \lambda \mathbf{Reg}(\mathcal{W}_t, \mathcal{E}) E(Wt​,V,Dt​,E)=Data(Wt​,V,Dt​)+λReg(Wt​,E) 其中数据项为稠密的model-to-frame的ICP，正则项惩罚不平滑的运动场，保证由边集E\mathcal{E}E连接的变换node之间的ARAP（as-rigid-as-possible）形变。 数据项 目标是估计非刚体变换参数，每个点对应的Tic\mathbf{T}_{ic}Tic​和公共变换Tlw\mathbf{T}_{lw}Tlw​，warp canonical体素到实时帧中。 mesh由点-法线对存储在canonical帧中：V^c≡{Vc,Nc}\mathcal{\hat{V}}_c \equiv \{ V_c, N_c \}V^c​≡{Vc​,Nc​}，将该mesh用Wt\mathcal{W}_tWt​非刚性变换得到实时warp后的点-法线对V^w\mathcal{\hat{V}}_wV^w​，warp后的与对应的实时深度数据之间构造数据项。 在model几何和实时帧之间初始的数据对应估计，通过将V^w\mathcal{\hat{V}}_wV^w​渲染到使用rasterizing渲染流程的由canonical帧顶点坐标shade的实时帧中（关于rasterizing请参考该链接）。将得到在实时帧中可见的canonical帧的几何：P(V^c)\mathcal{P}(\mathcal{\hat{V}}_c)P(V^c​)。 作为非刚体优化的先验，当给定一帧新的数据时，首先使用KinectFusion的稠密ICP方法得到公共变换因子Tlw\mathbf{T}_{lw}Tlw​。然后在当前可见的canonical几何对应的当前帧像素区域Ω\OmegaΩ中，构造每个点model-to-frame的point-plane误差为数据项 Data(W,V,Dt)≡∑u∈Ωψdata(n^u⊤(v^u−vlu~))\mathbf{Data}(\mathcal{W}, \mathcal{V}, D_t) \equiv \sum _{u \in \Omega} \psi _\mathbf{data} (\mathbf{\hat{n}}_u^\top (\mathbf{\hat{v}}_u - \mathbf{vl}_{\tilde{u}})) Data(W,V,Dt​)≡u∈Ω∑​ψdata​(n^u⊤​(v^u​−vlu~​)) 其中ψdata\psi _{\mathbf{data}}ψdata​ 为Tukey惩罚函数， [vl(u)⊤,1]⊤=K−1Dt(u)[u⊤,1]⊤T~u=W(v(u))v^u=T~uv(u)n^u=T~un(u)u~=π(Kv^u)\begin{aligned} \lbrack \mathbf{vl}(u)^\top , 1 \rbrack ^\top &= \mathbf{K}^{-1} D_t(u) \lbrack u^\top , 1 \rbrack ^\top \\ \mathbf{\tilde{T}}^u &= \mathcal{W} (\mathbf{v} (u)) \\ \mathbf{\hat{v}}_u &= \mathbf{\tilde{T}}^u \mathbf{v}(u) \\ \mathbf{\hat{n}}_u &= \mathbf{\tilde{T}}^u \mathbf{n}(u) \\ \tilde{u} &= \pi (\mathbf{K} \mathbf{\hat{v}}_u) \end{aligned} [vl(u)⊤,1]⊤T~uv^u​n^u​u~​=K−1Dt​(u)[u⊤,1]⊤=W(v(u))=T~uv(u)=T~un(u)=π(Kv^u​)​ 第一个公式计算当前深度图像素对应点的坐标，第二到第四公式计算由canonical帧中warp后的点和法线，第五个公式寻找对应关系。 正则项 数据项计算当前可见的形变，但是还有一个关键问题是当前不可见部分的形变也要估计，因此加入了正则项。 基于形变图模型定义正则项，如果node iii 和 jjj 之间存在边则增加一个ARAP正则项到全局能量中最小化 Reg(W,E)=∑i=0n∑j∈E(i)αijψreg(Ticdgvj−Tjcdgvj)\mathbf{Reg}(\mathcal{W}, \mathcal{E}) = \sum ^n _{i=0} \sum _{j \in \mathcal{E}(i)} \alpha_{ij} \psi_{\mathbf{reg}} (\mathbf{T}_{ic} \mathbf{dg}^j_v - \mathbf{T}_{jc} \mathbf{dg}^j_v) Reg(W,E)=i=0∑n​j∈E(i)∑​αij​ψreg​(Tic​dgvj​−Tjc​dgvj​) ψreg\psi_{\mathbf{reg}}ψreg​为Huber惩罚函数，E\mathcal{E}E定义了正则化的图拓扑，αij\alpha_{ij}αij​为边的权重αij=max⁡(dgwi,dgwj)\alpha_{ij} = \max (\mathbf{dg}^i_w, \mathbf{dg}^j_w)αij​=max(dgwi​,dgwj​)。 扩大warp场 原有的warp场node无法覆盖新增的数据时，需要扩大warp场。包括增量式更新形变图node Nwarp\mathcal{N}_{\mathbf{warp}}Nwarp​并重新计算新的分层边拓扑E\mathcal{E}E。 当 min⁡k∈N(xc)(∥dgvk−vc∥dgwk)≥1\min _{k \in N(x_c)} \left( \frac{\lVert \mathbf{dg}_v^k - v_c \rVert}{\mathbf{dg}^k_w} \right) \ge 1mink∈N(xc​)​(dgwk​∥dgvk​−vc​∥​)≥1 时，被认为不支持的顶点（vertex）。对于不支持的顶点使用下采样寻找新的node（详细描述看论文）。 给到新增的node之后，需要重新计算边。构造一个层数L≥1L \ge 1L≥1的正则图node分层，l=0l = 0l=0层node简单设为Nwarp\mathcal{N} _{\mathbf{warp}}Nwarp​。计算l=1l = 1l=1层的正则node，通过在warp场node dgv\mathbf{dg}_vdgv​ 上，基于半径搜索的下采样到增加的decimation半径 ϵβl,β>1\epsilon \beta ^l,\beta > 1ϵβl,β>1。再次通过DQB使用当前更新的Wt\mathcal{W}_tWt​计算初始node变换。反复如此到指定层数。新的边集E\mathcal{E}E开始于l=0l = 0l=0的Nwarp\mathcal{N}_{\mathbf{warp}}Nwarp​到位于l=1l = 1l=1的Nreg\mathcal{N}_{\mathbf{reg}}Nreg​，finer层中每个node增加的边都连到coarser层中的kkk近邻。]]></content>
      <tags>
        <tag>non-rigid</tag>
        <tag>3D Reconstruct</tag>
        <tag>Dynamic</tag>
        <tag>RGBD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[statismo代码分析--statismo-build-gp-model]]></title>
    <url>%2Farchives%2F23376.html</url>
    <content type="text"><![CDATA[使用高斯过程描述形变场，输入的数据只需要参考帧就行。需要设定kernel，由参考帧和kernel生成model 命令行参数 -t, --type TYPE : 指定模型是shape还是deformation -d, --dimensionality : 输入数据的维度，当TYPE为deformation时有效 -k, --kernel KERNEL : 指定高斯过程的kernel，默认只支持gaussian -p, --parameters KERNEL_PARAMETERS : kernel的参数，gaussian只有一个sigma参数 -s, --scale SCALE : 作用在kernel上的scaling参数 -n, --numberofbasisfunctions NUMBER_OF_BASIS_FUNCTIONS : 这个model需要的参数个数 -r, --reference REFERENCE_FILE : reference文件路径 -o, --output-file OUTPUT_FILE : 输出文件路径 -m, --input-model MODEL_FILE : 已有model的文件路径，用于扩展当前已有的model kernel的代码 在文件 utils/statismo-build-gp-model-kernels.h 中添加kernel，在这里kernel是对应的一对点计算得到的一个值，并非对应点的每个元素得到的每个一个对应向量 截取guassian kernel代码 在对应的头文件中定义类似的模板类，内联重载运算符()设定具体的kernel函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 用法，opt.vKernelParameters指定kernel类型typedef typename DataType::PointType PointType;typedef boost::scoped_ptr MatrixPointerType; MatrixPointerType pKernel;if (isShapeModel == true) { pKernel.reset((statismo::ScalarValuedKernel *) it->second.createKernelShape(opt.vKernelParameters));} else { if (Dimenstionality == Dimensionality2D) { pKernel.reset((statismo::ScalarValuedKernel *)it->second .createKernel2DDeformation(opt.vKernelParameters)); } else { pKernel.reset((statismo::ScalarValuedKernel *)it->second .createKernel3DDeformation(opt.vKernelParameters)); }}//////////////////////////////////////////////////////////////////////////template class GaussianKernel : public statismo::ScalarValuedKernel {public: // 这两个必须要有，并且不能边 typedef typename TPoint::CoordRepType CoordRepType; typedef vnl_vector VectorType; // 只有一个参数sigma GaussianKernel(double sigma) : m_sigma(sigma), m_sigma2(-1.0 / (sigma * sigma)) {} // 内联重载操作符()，定义kernel计算 // kernel是一个二元函数，返回kernel函数值 inline double operator()(const TPoint &x, const TPoint &y) const { VectorType xv = x.GetVnlVector(); VectorType yv = y.GetVnlVector(); VectorType r = yv - xv; return exp((double)dot_product(r, r) * m_sigma2); } std::string GetKernelInfo() const { std::ostringstream os; os < op1->cond1 cond1(no)->io2->ed cond1(yes)->cond2 cond2(yes)->op2->op5 cond2(no)->cond3 cond3(no)->op3->op5 cond3(yes)->op4->op5 op5->cond4 cond4(yes,right)->op6->op7 cond4(no)->io3->op7 op7->io4->ed{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <tags>
        <tag>statismo</tag>
        <tag>code</tag>
        <tag>SSM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[statismo代码分析--statismo-build-deformation-model]]></title>
    <url>%2Farchives%2F26365.html</url>
    <content type="text"><![CDATA[输入数据是形变场不是shape，对应的是reference mesh上每个点的形变方向，所以只需要输入数据对应，不需要align。但是最后得到的结果也是描述形变场的model，由这个model得到的形变场最后要加上reference mesh才能得到最后的shape。 命令行参数 -l, --data-list DATA_LIST ：指定一个文件路径，这个文件包含所有用来生成模型的形变场文件路径,每一行只写一个文件 -o, --output-file OUTPUT_FILE ：输出模型文件的路径 -n, --noise NOISE ：指定PPCA(probabilistic principal component analysis)模型的噪声方差，默认为0 -d, --dimensionality ：使用数据建立的模型维度，默认为3 代码 代码详细解释请参考另一篇文章st=>start: 开始 ed=>end: 退出 io1=>inputoutput: 输入命令行参数 op1=>operation: 读取命令行参数 cond1=>condition: 参数是否 符合要求？ io2=>inputoutput: 无法执行 cond2=>condition: 是否为2维？ (否为3维) op2=>operation: 设置为2维运算 op3=>operation: 设置为3维运算 op4=>operation: 读入数据,将第一帧 数据设为reference op5=>operation: 进行PCA io3=>inputoutput: 保存model st->io1->op1->cond1 cond1(no)->io2->ed cond1(yes)->cond2 cond2(yes, right)->op2->op4 cond2(no)->op3->op4 op4->op5->io3->ed{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <tags>
        <tag>statismo</tag>
        <tag>code</tag>
        <tag>SSM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[statismo代码分析--statismo-build-shape-model]]></title>
    <url>%2Farchives%2F34417.html</url>
    <content type="text"><![CDATA[statismo中statismo-build-shape-model程序代码的解读 总结一下就是：给出参考帧（因为PCA需要先中心化）之后PCA 流程图 命令行参数 -l, --data-list DATA_LIST ：指定一个文件路径，这个文件包含所有用来生成模型的mesh文件路径,每一行只写一个文件 -o, --output-file OUTPUT_FILE ：输出模型文件的路径 -p, --procrustes PROCRUSTES_MODE ：选择数据对齐（aligned）模式。如果选择reference，所有的数据和指定的参考mesh对齐；如果选择GPA，则和均值对齐 -r, --reference FILE ：在PROCRUSTES_MODE选择reference之后，指定参考mesh -n, --noise NOISE ：指定PPCA(probabilistic principal component analysis)模型的噪声方差，默认为0 读入mesh文件的代码 1234567891011121314151617typedef itk::MeshFileReader MeshReaderType;typedef vector MeshReaderList;MeshReaderList meshes;meshes.reserve(fileNames.size());for (StringList::const_iterator it = fileNames.begin(); it != fileNames.end(); ++it) { MeshReaderType::Pointer reader = MeshReaderType::New(); reader->SetFileName(it->c_str()); reader->Update(); //这段注释是说Update()这个函数很重要 // itk::PCAModelBuilder is not a Filter in the ITK world, so the pipeline // would not get executed if its main method is called. So the pipeline // before calling itk::PCAModelBuilder must be executed by the means of calls // to Update() (at least for last elements needed by itk::PCAModelBuilder). meshes.push_back(reader);} 关于为什么要用Update()的解释: You only have to call Update() on the last filter in your pipeline. The rest of this answer is the explanation. ITK uses a pipeline execution framework for filters. Assume we have three filters that are connected sequentially like the following: input --> |filter1| --> |filter2| --> |filter3| --> output If you call Update() on filter3, ITK starts from filter3 and checks if the input(s) to each filter have changed. If they have, ITK calls update on them in turn. See slide 5 of this link. 计算平均mesh作为参考mesh的代码 originalMeshes传入的是meshes的指针，也就是align也会影响meshes 12345678910111213141516171819202122232425262728293031typedef itk::Mesh MeshType;///////////////////////////////////////////////////////////////// 将已经读入的mesh都拷贝过来，mesh为之前读入的文件vector originalMeshes;for (MeshReaderList::iterator it = meshes.begin(); it != meshes.end(); ++it) { MeshReaderType::Pointer reader = *it; originalMeshes.push_back(reader->GetOutput());}const unsigned uMaxGPAIterations = 20;const unsigned uNumberOfPoints = 100; // 最多使用这么多个点const float fBreakIfChangeBelow = 0.001f;typedef itk::VersorRigid3DTransform Rigid3DTransformType;typedef itk::Image ImageType;typedef itk::LandmarkBasedTransformInitializer LandmarkBasedTransformInitializerType;typedef itk::TransformMeshFilter FilterType;// 计算参考meshMeshType::Pointer referenceMesh = calculateProcrustesMeanMesh( originalMeshes, uMaxGPAIterations, uNumberOfPoints, fBreakIfChangeBelow);representer->SetReference(referenceMesh);SetIdentity(); landmarkBasedTransformInitializer->SetTransform(transform); landmarkBasedTransformInitializer->InitializeTransform(); // 使用计算得到的刚体变换进行align，这里是mesh上所有的点 typename FilterType::Pointer filter = FilterType::New(); filter->SetInput(movingMesh); filter->SetTransform(transform); filter->Update(); *it = filter->GetOutput(); } return translatedMeshes;} 计算平均mesh的函数 遍历求和，然后遍历求平均 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788template typename MeshType::PointercalculateMeanMesh(std::vector meshes) { // 必须要存在mesh if (meshes.size() == 0) { itkGenericExceptionMacro( < GetNumberOfPoints() * MeshType::PointDimension; vMeshPoints.reserve(uDataSize); for (int i = 0; i < uDataSize; ++i) { CompensatedSummationType sum; vMeshPoints.push_back(sum); } // 遍历每个mesh // 求和 for (typename std::vector::const_iterator i = meshes.begin(); i != meshes.end(); ++i) { typename MeshType::Pointer pMesh = *i; // 验证向量维度(点的个数和点的维度)要一样 if (vMeshPoints.size() != pMesh->GetNumberOfPoints() * MeshType::PointDimension) { itkGenericExceptionMacro( < GetPoints()->Begin(); // sum up all meshes // 遍历这个mesh的每个点 for (; pointData != pMesh->GetPoints()->End(); ++pointData) { const typename MeshType::PointType point = pointData->Value(); // 遍历这个点的每个维度 // 将对应维度的数值加入vMeshPoints中 for (typename MeshType::PointType::ConstIterator pointIter = point.Begin(); pointIter != point.End(); ++pointIter, ++sum) { (*sum) += *pointIter; } } } float fInvNumberOfMeshes = 1.0f / meshes.size(); // 虽然是复制的第一帧mesh，但是后面是直接覆盖 typename MeshType::Pointer pMeanMesh = cloneMesh(pFirstMesh); // write the data to the mean mesh typename MeshPointsVectorType::iterator sum = vMeshPoints.begin(); // 遍历meanmesh的每个点 // 计算平均值 for (typename MeshType::PointsContainer::Iterator pointData = pMeanMesh->GetPoints()->Begin(); pointData != pMeanMesh->GetPoints()->End(); ++pointData) { // 遍历点的每个维度 for (typename MeshType::PointType::Iterator pointIter = pointData->Value().Begin(); pointIter != pointData->Value().End(); ++pointIter, ++sum) { // 计算平均值传给meanmesh *pointIter = sum->GetSum() * fInvNumberOfMeshes; } } return pMeanMesh;} 计算平均mesh和当前参考mesh的差值 每对对应点的距离求和，再除以shape向量的整体维度进行平均 12345678910111213141516171819202122232425template float calculateMeshDistance(typename MeshType::Pointer mesh1, typename MeshType::Pointer mesh2) { // 点数和拓扑要一样（实际上也需要完全对应） if (mesh1->GetNumberOfPoints() != mesh2->GetNumberOfPoints() || mesh1->GetNumberOfCells() != mesh2->GetNumberOfCells()) { itkGenericExceptionMacro( < GetPoints()->Begin(); IteratorType point2 = mesh2->GetPoints()->Begin(); // 每对对应点的距离求和 for (; point1 != mesh1->GetPoints()->End(); ++point1, ++point2) { fDifference += point1->Value().SquaredEuclideanDistanceTo(point2->Value()); } // 除以（mesh点的个数 乘上 点的维度） fDifference /= (mesh1->GetNumberOfPoints() * MeshType::PointDimension); return fDifference;} 将参考帧加入数据管理 1234567891011typedef itk::Mesh MeshType;typedef itk::DataManager DataManagerType;DataManagerType::Pointer dataManager = DataManagerType::New();////////////////////////////////////////////////////////////////////dataManager->SetRepresenter(representer);for (MeshReaderList::const_iterator it = meshes.begin(); it != meshes.end(); ++it) { MeshReaderType::Pointer reader = *it; dataManager->AddDataset(reader->GetOutput(), reader->GetFileName());} 进行PCA并保存model 这个PCA之前没有align的过程？？GPA会进行align，但是如果选择reference这里就没有进行align了？ 123456789101112// model类型typedef itk::StatisticalModel StatisticalModelType;StatisticalModelType::Pointer model;// 进行PCAtypedef itk::PCAModelBuilder PCAModelBuilder;PCAModelBuilder::Pointer pcaModelBuilder = PCAModelBuilder::New();// 直接就进行PCA了model = pcaModelBuilder->BuildNewModel(dataManager->GetData(), opt.fNoiseVariance);// 保存为文件itk::StatismoIO::SaveStatisticalModel( model, opt.strOutputFileName.c_str()); PCA函数 比较常规的PCA计算过程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849template PCAModelBuilder::PCAModelBuilder() : Superclass() {}template typename PCAModelBuilder::StatisticalModelType *PCAModelBuilder::BuildNewModel(const DataItemListType &sampleDataList, double noiseVariance, bool computeScores, EigenValueMethod method) const { // 设定数据样本个数 unsigned n = sampleDataList.size(); if (n GetSampleVector().rows(); const Representer *representer = sampleDataList.front()->GetRepresenter(); // Compute the mean vector mu // 求和在平均得到重心 VectorType mu = VectorType::Zero(p); for (typename DataItemListType::const_iterator it = sampleDataList.begin(); it != sampleDataList.end(); ++it) { assert((*it)->GetSampleVector().rows() == p); // all samples must have same number of rows assert((*it)->GetRepresenter() == representer); // all samples have the same representer mu += (*it)->GetSampleVector(); } mu /= n; // Build the mean free sample matrix X0 // 减去重心，中心化 MatrixType X0(n, p); unsigned i = 0; for (typename DataItemListType::const_iterator it = sampleDataList.begin(); it != sampleDataList.end(); ++it) { X0.row(i++) = (*it)->GetSampleVector() - mu; } // build the model // 使用SVD或者特征值分解等方式计算 StatisticalModelType *model = BuildNewModelInternal(representer, X0, mu, noiseVariance, method); ... return model;} st=>start: 开始 ed=>end: 退出 io1=>inputoutput: 输入命令行参数 op1=>operation: 读取命令行参数 cond1=>condition: 参数是否 符合要求？ io2=>inputoutput: 无法执行 op2=>operation: 读入mesh文件 cond2=>condition: 输入参数是否设 置了参考mesh？ op3=>operation: 按照设置选择已有 mesh为参考mesh op4=>operation: 计算参考mesh (有相关代码详解) op5=>operation: 设定参考mesh并将每 帧mesh加入数据管理 op6=>operation: 进行PCA io3=>inputoutput: 保存model文件 st->io1->op1->cond1 cond1(no)->io2->ed cond1(yes)->op2->cond2 cond2(yes, right)->op3->op5 cond2(no)->op4->op5 op5->op6->io3->ed{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <tags>
        <tag>statismo</tag>
        <tag>code</tag>
        <tag>SSM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bundle Adjustment简述]]></title>
    <url>%2Farchives%2F58892.html</url>
    <content type="text"><![CDATA[笔者到底想讲些啥？ 在SFM（structure from motion）的计算中BA（Bundle Adjustment）作为最后一步优化具有很重要的作用，在近几年兴起的基于图的SLAM（simultaneous localization and mapping）算法里面使用了图优化替代了原来的滤波器，这里所谓的图优化其实也是指BA。其实很多经典的文献对于BA都有深深浅浅的介绍，如果想对BA的全过程做一个全面的更深层次的了解，推荐阅读 Bundle Adjustment —A Modern Synthesis，但是BA的内容确实太多太杂了，刚对其了解的时候往往会陷入其局部的计算中不能自拔，因此笔者准备对其进行一个比较全局一点的介绍，希望读者可以比较轻松的一览BA的全过程而不是陷入其局部的繁琐的计算中，同时也会尽量对其需要的数学工具介绍全面，如有错误和遗漏还望指正。 如果读者对以下内容有基本了解那可就太棒棒了！ 射影相机几何模型 对极几何 凸优化 矩阵理论 这才是真的开始 Bundle Adjustment（之后在不引起歧义的情况下用BA代替，你问为什么？笔者懒啊-。-），大概似乎也许好像有近百年的历史了吧（没错，可以称为state-of-art的视觉SLAM在几年前才用上将近上百岁的算法），中文译为光束法平差，大概大家看到更多的翻译可能为束调整、捆集调整或者捆绑调整等等。这么多翻译笔者最喜欢的还是光束法平差，一看就比其它的更专业逼格更高嘛，其它的翻译都太直译了。当然最重要的是光束法平差完美的表达了BA的来源、原理和计算过程，而其他的只是强调了将很多数据放在一起进行优化计算这个事。不信？那我们来分析一下嘛。 所谓bundle，来源于bundle of light，其本意就是指的光束，这些光束指的是三维空间中的点投影到像平面上的光束，而重投影误差（后面会讲这到底是个什么鬼）正是利用这些光束来构建的，因此称为光束法强调光束也正是描述其优化模型是如何建立的。剩下的就是平差，那什么是平差呢？借用一下百度词条 测量平差 中的解释吧。 由于测量仪器的精度不完善和人为因素及外界条件的影响，测量误差总是不可避免的。为了提高成果的质量，处理好这些测量中存在的误差问题，观测值的个数往往要多于确定未知量所必须观测的个数，也就是要进行多余观测。有了多余观测，势必在观测结果之间产生矛盾，测量平差的目的就在于消除这些矛盾而求得观测量的最可靠结果并评定测量成果的精度。测量平差采用的原理就是“最小二乘法”。 平差也就正好表述了为什么需要BA以及BA这个优化过程到底是怎么进行的。 BA模型到底是怎么来的？ 感觉前面废话说了一大堆，解释了半天BA的中文翻译，那么BA到底是干嘛的呢？经过前面的铺垫，用一句话来描述BA那就是，BA的本质是一个优化模型，其目的是最小化重投影误差 本质是一个优化模型应该很容易理解，那么什么是重投影误差呢？投影自然是个几何的问题，既然是几何问题那这个时候来个图自然就是最棒棒了！ 看！这些五颜六色的线就是我们讲的光束啦！那现在就该说下什么叫重投影误差了，重投影也就是指的第二次投影，那到底是怎么投影的呢？我们来整理一下吧： 其实第一次投影指的就是相机在拍照的时候三维空间点投影到图像上 然后我们利用这些图像对一些特征点进行三角定位（triangulation，很多地方翻译为三角化或者三角剖分等等，当然笔者最喜欢的还是三角定位，显然是利用几何信息构建三角形来确定三维空间点的位置嘛，相关内容请参考对极几何） 最后利用我们计算得到的三维点的坐标（注意不是真实的）和我们计算得到的相机矩阵（当然也不是真实的）进行第二次投影，也就是重投影 现在我们知道什么是重投影了，那重投影误差到底是什么样的误差呢？这个误差是指的真实三维空间点在图像平面上的投影（也就是图像上的像素点）和重投影（其实是用我们的计算值得到的虚拟的像素点）的差值，因为种种原因计算得到的值和实际情况不会完全相符，也就是这个差值不可能恰好为0，此时也就需要将这些差值的和最小化获取最优的相机参数及三维空间点的坐标。 进入数学模式！ 感觉像写小说一样写了一堆堆的文字，既然BA是个数学问题，不用数学讲讲好像不太行，接下来就看看BA的数学模型是怎么构建的吧。 对BA有点了解的同学可能知道BA是一个图优化模型，那首先肯定要构造一个图模型了（没学过图论也没事，后面还是会回到一般的优化模型）。既然是图模型那自然就有节点和边了，这个图模型的节点由相机PiP_iPi​和三维空间点构成XjX_jXj​构成，如果点XjX_jXj​投影到相机PiP_iPi​的图像上则将这两个节点连接起来。还是来张图吧。 这样就一目了然了。那么我们现在就可以通过这个图来构造优化模型了。 令点XjX_jXj​在相机PiP_iPi​拍摄到的图像归一化坐标系上的坐标为k(uijT,1)T=Ki−1xijk(u_{ij}^T,1)^T=K_i^{-1}x_{ij}k(uijT​,1)T=Ki−1​xij​，其重投影后的图像归一化坐标系下坐标为k′(vijT,1)T=Ki−1PiXjk'(v_{ij}^T,1)^T=K_i^{-1}P_iX_jk′(vijT​,1)T=Ki−1​Pi​Xj​，其中Ki−1K_i^{-1}Ki−1​是为了在计算时能不受相机内参影响kkk和k′k'k′是将齐次坐标转换为非齐次坐标的常数项，可以得到该重投影误差为 eij=∥uij−vij∥e_{ij}=\|u_{ij}-v_{ij}\| eij​=∥uij​−vij​∥ BA是要将所有重投影误差的和最小化，那么这里自然就要开始求和了。 min⁡Ri,ti,Xj∑i,jσij∥uij−vij∥\min_{R_i,t_i,X_j} \sum_{i,j} \sigma_{ij}\|u_{ij}-v_{ij}\| Ri​,ti​,Xj​min​i,j∑​σij​∥uij​−vij​∥ 其中当点XjX_jXj​在相机PiP_iPi​中有投影时σij=1\sigma_{ij}=1σij​=1，否则为σij=0\sigma_{ij}=0σij​=0。 到此我们就得到了BA优化模型的数学形式了。 接下来就应该开始计算了！ 既然是优化模型，那自然就应该用各种优化算法来进行计算了。这里先小小的剧透一下，BA现在基本都是利用LM（Levenberg-Marquardt）算法并在此基础上利用BA模型的稀疏性质来进行计算的，LM算法是最速下降法（梯度下降法）和Gauss-Newton的结合体，至于是怎么结合的接下来就来慢慢介绍了。 最速下降法 如果你对梯度比较熟悉的话，那你应该知道梯度方向是函数上升最快的方向，而此时我们需要解决的问题是让函数最小化。你应该想到了，那就顺着梯度的负方向去迭代寻找使函数最小的变量值就好了嘛。梯度下降法就是用的这种思想，用数学表达的话大概就是这样 xk=xk−1−λ∇f(xk−1)x_k = x_{k-1}-\lambda \nabla f(x_{k-1}) xk​=xk−1​−λ∇f(xk−1​) 其中λ\lambdaλ为步长。 最速下降法保证了每次迭代函数都是下降的，在初始点离最优点很远的时候刚开始下降的速度非常快，但是最速下降法的迭代方向是折线形的导致了收敛非常非常的慢。 Newton型方法 现在先回顾一下中学数学，给定一个开口向上的一元二次函数，如何知道该函数何处最小？这个应该很容易就可以答上来了，对该函数求导，导数为000处就是函数最小处。 Newton型方法也就是这种思想，首先将函数利用泰勒展开到二次项： f(x+δx)≈φ(δx)=f(x)+J(x)δx+12δxTH(x)δx\mathbf{f(x + \delta x) \approx \varphi(\delta x) = f(x) + J(x)\delta x + \frac{1}{2}\delta x^T H(x) \delta x} f(x+δx)≈φ(δx)=f(x)+J(x)δx+21​δxTH(x)δx 其中J\mathbf{J}J为Jacobi矩阵，对矩阵函数求一次偏导而来，梯度也是对向量函数求一次偏导而来。将标量考虑为1×11 \times 11×1的矩阵，将向量考虑为n×1n \times 1n×1的矩阵，其实这些求导都是求Jacobi矩阵。H\mathbf{H}H为Hessian矩阵，也就是二次偏导矩阵。 也就是说Newton型方法将函数局部近似成一个二次函数进行迭代，然后令x\mathbf{x}x在δx\mathbf{\delta x}δx方向上迭代直至收敛，接下来自然就对这个函数求导了： φ′(δx)=J+Hδx=0\mathbf{\varphi'(\delta x) = J + H \delta x = 0 } φ′(δx)=J+Hδx=0 ⟹δx=−H−1J\Longrightarrow \mathbf{ \delta x = -H^{-1}J } ⟹δx=−H−1J Newton型方法收敛的时候特别快，尤其是对于二次函数而言一步就可以得到结果。但是该方法有个最大的缺点就是Hessian矩阵计算实在是太复杂了，并且Newton型方法的迭代并不像最速下降法一样保证每次迭代都是下降的。 Gauss-Newton方法 既然Newton型方法计算Hessian矩阵太困难了，那有没有什么方法可以不计算Hessian矩阵呢？将泰勒展开式的二次项也去掉好像就可以避免求Hessian矩阵了吧，就像这样： f(x+δx)≈f(x)+J(x)δx\mathbf{f(x + \delta x) \approx f(x) + J(x)\delta x} f(x+δx)≈f(x)+J(x)δx 这好像变成了一个线性函数了啊，线性函数如果要最小化的话好像是需要增加其他的约束条件的啊。那这里有没有其他的约束条件呢？仔细思考一下，我们需要最小化的是重投影误差eij=∥uij−vij∥e_{ij}=\|u_{ij}-v_{ij}\|eij​=∥uij​−vij​∥，它的最小值是什么呢？理想状态下当然是等于000了。所以这个时候就不应该求导了，而是直接令函数为000。此时，令f(x)=ε\mathbf{f(x) = \varepsilon}f(x)=ε有 ε+Jδx=0\mathbf{\varepsilon + J \delta x = 0} ε+Jδx=0 ⟹JTJδx=−JTε\Longrightarrow \mathbf{J^{T} J \delta x = - J^{T} \varepsilon} ⟹JTJδx=−JTε x=x+δx\mathbf{x = x + \delta x} x=x+δx 由此x\mathbf{x}x在δx\mathbf{\delta x}δx方向上迭代直至∥ε∥\| \varepsilon \|∥ε∥最小。 Gauss-Newton方法就避免了求Hessian矩阵，并且在收敛的时候依旧很快。但是依旧无法保证每次迭代的时候函数都是下降的。 LM方法 LM方法就是在以上方法基础上的改进，通过参数的调整使得优化能在最速下降法和Gauss-Newton法之间自由的切换，在保证下降的同时也能保证快速收敛。 Gauss-Newton最后需要求解的方程为 JTJδx=−JTε\mathbf{J^{T} J \delta x = - J^{T} \varepsilon} JTJδx=−JTε LM算法在此基础上做了更改，变成了 (JTJ+λI)δx=−JTε\mathbf{(J^{T} J + \lambda I) \delta x = - J^{T} \varepsilon} (JTJ+λI)δx=−JTε 通过参数λ\lambdaλ的调节在最速下降法和Gauss-Newton法之间切换。做个不很数学的直观分析吧，当λ\lambdaλ很小时，显然和Gauss-Newton法是一样的；当λ\lambdaλ很大时，就变成了这样： λIδx=−JTϵ\mathbf{\lambda I \delta x = - J^T \epsilon} λIδx=−JTϵ ⟹δx=−λ−1JTϵ\Longrightarrow \mathbf{\delta x = - \lambda^{-1}J^T \epsilon} ⟹δx=−λ−1JTϵ 然后再看看前面的最速下降法？ 这里还存在一个问题，当λ\lambdaλ取某个值的时候可能会导致JJ+λI\mathbf{J^J + \lambda I}JJ+λI不可逆，所以这里变成了 (JTJ+λdiag(JTJ))δx=−JTε\mathbf{(J^{T} J + \lambda diag(J^T J)) \delta x = - J^{T} \varepsilon} (JTJ+λdiag(JTJ))δx=−JTε 其实LM算法的具体形式就笔者看到的就有很多种，但是本质都是通过参数λ\lambdaλ在最速下降法和Gauss-Newton法之间切换。这里选用的是维基百科上的形式。 LM算法就由此保证了每次迭代都是下降的，并且可以快速收敛。 还没完呢！别忘了还要解方程 LM算法主体就是一个方程的求解，也是其计算量最大的部分。当其近似于最速下降法的时候没有什么好讨论的，但是当其近似于Gauss-Newton法的时候，这个最小二乘解的问题就该好好讨论一下了。以下的讨论就利用Gauss-Newton的形式来求解。 稠密矩阵的最小二乘解 对于形如Ax=bAx=bAx=b的超定参数方程而言，有很多求解方式，伪逆、QR分解、SVD等等，这里不展开谈，想具体了解的可以去查阅矩阵理论相关资料。这些方式都有一个共同的特点，我们都是将AAA看作一般的稠密矩阵，主要得到的解自然非常鲁棒，都是计算量却是和维数的三次方成正比（O(n3)O(n^3)O(n3)）。面对BA这种超大规模的优化似乎有点不太实用。 稀疏矩阵的Cholesky分解 稠密矩阵计算起来那么复杂，如果是稀疏矩阵的话利用其稀疏的性质可以大幅减少计算量，对于稀疏矩阵的Cholesky分解就是这样。其分解形式为一个上三角矩阵的转置乘上自身： A≈RTRA \approx R^T R A≈RTR RTRx=bR^TRx = b RTRx=b x=R−1R−Tbx = R^{-1}R^{-T}b x=R−1R−Tb 为什么说我们的矩阵是稀疏的 用一个非常简单的例子来解释吧，考虑有两个相机矩阵P1P_1P1​和P2P_2P2​、两个空间点X1X_1X1​和X2X_2X2​，其中X1X_1X1​只在P2P_2P2​中有投影，X2X_2X2​在两个相机（或视角）中都有投影。令优化函数为f(P1,P2,X1,X2)f(P_1,P_2,X_1,X_2)f(P1​,P2​,X1​,X2​)，此时Jacobi矩阵为 J=[∂f∂P1∂f∂X2∂f∂P2∂f∂X1∂f∂P2∂f∂X2]\mathbf{J} = \left[ \begin{array}{cc|cc} \frac{\partial f}{\partial P_1} & & & \frac{\partial f}{\partial X_2} \\\\ & \frac{\partial f}{\partial P_2} & \frac{\partial f}{\partial X_1} & \\\\ & \frac{\partial f}{\partial P_2} & & \frac{\partial f}{\partial X_2} \end{array} \right] J=⎣⎢⎢⎢⎢⎢⎡​∂P1​∂f​​∂P2​∂f​∂P2​∂f​​∂X1​∂f​​∂X2​∂f​∂X2​∂f​​⎦⎥⎥⎥⎥⎥⎤​ 考虑相机位置（图像数量）和空间点都非常多的情况，不难想象Jacobi矩阵不光是一个稀疏矩阵而且还可以写成形如[A∣B][A|B][A∣B]的分块矩阵。接下来就该利用这些性质正式进入计算了！ 开始计算吧！ 现在再回到Gauss-Newton最后的超定参数方程吧。既然Jacobi矩阵可以分块那我们就先分块，分块可以有效降低需要计算的矩阵的维度并以此减少计算量。 JTJδx=−JTε\mathbf{J^{T} J \delta x = - J^{T} \varepsilon} JTJδx=−JTε J=[A∣B]\mathbf{J}=[A|B] J=[A∣B] [A∣B]T[A∣B]δx=−[A∣B]Tε[A|B]^T[A|B]\mathbf{\delta x}=-[A|B]^T \varepsilon [A∣B]T[A∣B]δx=−[A∣B]Tε [ATAATBBTABTB][δxAδxB]=−[ATεBTε]\begin{bmatrix} A^TA & A^TB \\\\ B^TA & B^TB \end{bmatrix} \begin{bmatrix} \mathbf{\delta x}_A \\\\ \mathbf{\delta x}_B \end{bmatrix} = - \begin{bmatrix} A^T \varepsilon \\\\ B^T \varepsilon \end{bmatrix} ⎣⎡​ATABTA​ATBBTB​⎦⎤​⎣⎡​δxA​δxB​​⎦⎤​=−⎣⎡​ATεBTε​⎦⎤​ [UWWTV][δxAδxB]=[εAεB]\begin{bmatrix} U & W \\\\ W^T & V \end{bmatrix} \begin{bmatrix} \mathbf{\delta x}_A \\\\ \mathbf{\delta x}_B \end{bmatrix} = \begin{bmatrix} \varepsilon _A \\\\ \varepsilon _B \end{bmatrix} ⎣⎡​UWT​WV​⎦⎤​⎣⎡​δxA​δxB​​⎦⎤​=⎣⎡​εA​εB​​⎦⎤​ [I−WV−10I][UWWTV][δxAδxB]=[I−WV−10I][εAεB]\begin{bmatrix} I & -WV^{-1} \\\\ 0 & I \end{bmatrix} \begin{bmatrix} U & W \\\\ W^T & V \end{bmatrix} \begin{bmatrix} \mathbf{\delta x}_A \\\\ \mathbf{\delta x}_B \end{bmatrix} = \begin{bmatrix} I & -WV^{-1} \\\\ 0 & I \end{bmatrix} \begin{bmatrix} \varepsilon _A \\\\ \varepsilon _B \end{bmatrix} ⎣⎡​I0​−WV−1I​⎦⎤​⎣⎡​UWT​WV​⎦⎤​⎣⎡​δxA​δxB​​⎦⎤​=⎣⎡​I0​−WV−1I​⎦⎤​⎣⎡​εA​εB​​⎦⎤​ [U−WV−1WT0WTV][δxAδxB]=[εA−WV−1εBεB]\begin{bmatrix} U-WV^{-1}W^T & 0 \\\\ W^T & V \end{bmatrix} \begin{bmatrix} \mathbf{\delta x}_A \\\\ \mathbf{\delta x}_B \end{bmatrix} = \begin{bmatrix} \varepsilon _ A - WV^{-1}\varepsilon _B \\\\ \varepsilon _B \end{bmatrix} ⎣⎡​U−WV−1WTWT​0V​⎦⎤​⎣⎡​δxA​δxB​​⎦⎤​=⎣⎡​εA​−WV−1εB​εB​​⎦⎤​ {(U−WV−1WT)δA=εA−WV−1εBWTδA+VδB=εB\begin{cases} (U-WV^{-1}W^T) \delta _A = \varepsilon _ A - WV^{-1}\varepsilon _B \\\\ W^T \delta _A + V \delta _B = \varepsilon _B \end{cases} ⎩⎪⎨⎪⎧​(U−WV−1WT)δA​=εA​−WV−1εB​WTδA​+VδB​=εB​​ 由此我们可以先求出δA\delta _AδA​，然后代回求出δB\delta _BδB​。其中U−WV−1WTU-WV^{-1}W^TU−WV−1WT被称为舒尔补（Schur complement）。分块降维之后的计算就可以利用稀疏的Cholesky分解进行计算了。 注意事项！ 以上就基本将BA的整个过程进行了介绍，当然这只是最基础的思路，接下来一些遗漏点进行补充。 李群及李代数 不知道有没有人注意到，在优化迭代的过程中，我们求的值为δx\delta xδx，然后利用x+δxx + \delta xx+δx来更新xxx的值。这里就应该出现一个问题了，对于空间点的坐标和平移向量这么处理自然没有什么问题，但是对于旋转矩阵呢？难道用R+δRR + \delta RR+δR来更新RRR的值吗？好像不太对吧。 对于旋转矩阵RRR而言是不存在加法的，按理讲应该用RδRR \delta RRδR来更新RRR的值，但是优化算法的迭代过程又不能是乘法，这就出现了矛盾。 这里旋转矩阵及相关运算属于李群，此时将旋转矩阵变换到其对应的李代数上进行计算，然后再变回李群。打个不是那么恰当的比方，在计算卷积的时候常常通过傅里叶变换计算乘积然后再反变换回来就是要求的卷积了，这个也是转换到李代数上计算然后再变回李群。具体的推导可以参看李群及李代数相关内容。 协方差矩阵 在我们的推导中是求解方程 JTJδx=−JTε\mathbf{J^{T} J \delta x = - J^{T} \varepsilon} JTJδx=−JTε 但常常加入信息矩阵（协方差矩阵的逆），令求解方程变为 JTΣx−1Jδx=−JTΣx−1ε\mathbf{J^{T} \Sigma_x^{-1} J \delta x = - J^{T} \Sigma_x^{-1} \varepsilon} JTΣx−1​Jδx=−JTΣx−1​ε 其中Σx\mathbf{\Sigma_x}Σx​为协方差矩阵，令其为分块对角阵表示所有观测向量都不相关。 参考文献 Triggs B, McLauchlan P F, Hartley R I, et al. Bundle adjustment—a modern synthesis[C]//International workshop on vision algorithms. Springer Berlin Heidelberg, 1999: 298-372. Hartley R, Zisserman A. Multiple view geometry in computer vision[M]. Cambridge university press, 2003. Barfoot T D. STATE ESTIMATION FOR ROBOTICS[J]. 2017.]]></content>
      <tags>
        <tag>BA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四元数及error-state kalman]]></title>
    <url>%2Farchives%2F31646.html</url>
    <content type="text"><![CDATA[四元数相关的基本推导，主要是扰动相关。然后记下了一些error-state kalman相关的公式。 不做具体说明时，都是右手系 四元数乘法 q⊗p≠p⊗qq \otimes p \neq p \otimes q q⊗p≠p⊗q 其中⊗\otimes⊗为四元数乘法，ppp和qqq为四元数，四元数乘法满足结合律和分配律。四元数乘法为二元运算，可以写成两种等价的形式： q⊗p=[q]Lp=[p]Rqq \otimes p = {[q]}_L p = {[p]}_Rq q⊗p=[q]L​p=[p]R​q [q]L=qwI+[0−qvTqv[qv]×][q]_L = q_wI + \begin{bmatrix} 0 & -q_v^T \\ q_v & [q_v]_{\times} \end{bmatrix} [q]L​=qw​I+[0qv​​−qvT​[qv​]×​​] [q]R=qwI+[0−qvTqv−[qv]×][q]_R = q_wI + \begin{bmatrix} 0 & -q_v^T \\ q_v & -[q_v]_{\times} \end{bmatrix} [q]R​=qw​I+[0qv​​−qvT​−[qv​]×​​] 其中q=(qw,qv)q = (q_w, q_v)q=(qw​,qv​)，qwq_wqw​为实数，qvq_vqv​为其中虚数向量。 左手系和右手系在四元数计算上的区别： 右手系：ij=−ji=kij = -ji = kij=−ji=k， jk=−kj=ijk = -kj = ijk=−kj=i，ki=−ik=jki = -ik = jki=−ik=j 左手系：ij=−ji=−kij = -ji = -kij=−ji=−k，jk=−kj=−ijk = -kj = -ijk=−kj=−i，ki=−ik=−jki = -ik = -jki=−ik=−j Eigen中的四元数运算如果使用方法 coeffs()输出系数，输出的向量是按照(qv,qw)(q_v,q_w)(qv​,qw​)排列的。在Eigen中四元数的构造函数中，输入参数顺序是按照(qw,qv)(q_w,q_v)(qw​,qv​)排列的。所以想使用四元数乘法的时候可以构造四元数使用Eigen的四元数相乘函数来避免这些问题。但是想使用Eigen的四元数系数进行四元数乘法运算时（尤其对于论文里面经常提到的Ω\OmegaΩ矩阵），其形式为 [q]L=qwI+[[qv]×qv−qvT0][q]_L = q_wI +\begin{bmatrix}[q_v]_{\times} & q_v \\-q_v^T & 0\end{bmatrix}[q]L​=qw​I+[[qv​]×​−qvT​​qv​0​] [q]R=qwI+[−[qv]×qv−qvT0][q]_R = q_wI +\begin{bmatrix}-[q_v]_{\times} & q_v \\-q_v^T & 0\end{bmatrix}[q]R​=qw​I+[−[qv​]×​−qvT​​qv​0​] 当然计算结果自然是按照(qv,qw)(q_v,q_w)(qv​,qw​)排列的四元数 由于 q⊗r⊗p=[p]R[q]Lrq \otimes r \otimes p = [p]_R[q]_Lr q⊗r⊗p=[p]R​[q]L​r q⊗r⊗p=[q]L[p]Rrq \otimes r \otimes p = [q]_L[p]_Rr q⊗r⊗p=[q]L​[p]R​r 因此有[p]R[q]L=[q]L[p]R[p]_R[q]_L = [q]_L[p]_R[p]R​[q]L​=[q]L​[p]R​ 扰动及求导 先交代一些东西 qAB⊗qBC=qACq_{AB} \otimes q_{BC} = q_{AC} qAB​⊗qBC​=qAC​ RABRBC=RACR_{AB} R_{BC} = R_{AC} RAB​RBC​=RAC​ Δq=[112Δθ]+O(∥Δθ∥2)\Delta q = \begin{bmatrix} 1 \\ \frac{1}{2} \Delta \theta \end{bmatrix} + O \left( \| \Delta \theta \|^2 \right) Δq=[121​Δθ​]+O(∥Δθ∥2) ΔR=I+[Δθ]×+O(∥Δθ∥2)\Delta R = I + [\Delta \theta]_{\times} + O\left( \| \Delta \theta \|^2 \right) ΔR=I+[Δθ]×​+O(∥Δθ∥2) 下文可能使用局部到全局坐标系的变换更容易理解 局部扰动 局部扰动也就是把扰动加在目前的坐标系数据下，然后再通过坐标系之间的关系变到其他坐标系下，具体形式为： q~=q⊗Δq\tilde{q} = q \otimes \Delta q q~​=q⊗Δq R~=RΔR\tilde{R} = R \Delta R R~=RΔR 其扰动放在右边，其原因为qAB′=qAB⊗qBB′q_{AB'} = q_{AB} \otimes q_{BB'}qAB′​=qAB​⊗qBB′​，可以满足先对局部数据进行扰动调整再通过坐标系关系变换到其他坐标系下。典型的应用为IMU预积分，具体形式为qGIk+1=qGIk⊗qIkIk+1q_{GI_{k+1}} = q_{GI_{k}} \otimes q_{I_{k}I_{k+1}}qGIk+1​​=qGIk​​⊗qIk​Ik+1​​。旋转矩阵形式类似。其对时间求导形式为： q˙=12Ω(ω)q=12q⊗ω\dot{q} = \frac{1}{2} \Omega(\omega) q = \frac{1}{2} q \otimes \omega q˙​=21​Ω(ω)q=21​q⊗ω R˙=R[ω]×\dot{R} = R[\omega]_{\times} R˙=R[ω]×​ 其中ω\omegaω为局部角速度（当前坐标系的角速度），Ω(ω)\Omega(\omega)Ω(ω)为[ω]R[\omega]_R[ω]R​（不要在意维数的问题）。具体推导如下： q˙=lim⁡Δt→0q(t+Δt)−q(t)Δt=lim⁡Δt→0q⊗Δq−qΔt=lim⁡Δt→0q⊗([1Δθ/2]−[10])Δt=lim⁡Δt→0q⊗([0Δθ/2])Δt=12q⊗[0ωL]R˙=lim⁡Δt→0R(t+Δt)−R(t)Δt=lim⁡Δt→0RΔR−RΔt=lim⁡Δt→0R(ΔR−I)Δt=lim⁡Δt→0R[Δθ]×Δt=R[ω]×\begin{aligned} \dot{q} &= \lim_{\Delta t \rightarrow 0} \frac{q(t + \Delta t) - q(t)}{\Delta t} \\ &= \lim_{\Delta t \rightarrow 0} \frac{q \otimes \Delta q - q}{\Delta t} \\ &= \lim_{\Delta t \rightarrow 0} \frac{q \otimes \left(\begin{bmatrix}1 \\ \Delta \theta/2 \end{bmatrix} - \begin{bmatrix} 1 \\ 0 \end{bmatrix} \right)}{\Delta t} \\ &= \lim_{\Delta t \rightarrow 0} \frac{q \otimes \left(\begin{bmatrix}0 \\ \Delta \theta/2 \end{bmatrix} \right)}{\Delta t} \\ &= \frac{1}{2} q \otimes \begin{bmatrix} 0 \\ \omega_L \end{bmatrix} \\ \\ \dot{R} &= \lim_{\Delta t \rightarrow 0} \frac{R(t + \Delta t) - R(t)}{\Delta t} \\ &= \lim_{\Delta t \rightarrow 0} \frac{R \Delta R - R}{\Delta t} \\ &= \lim_{\Delta t \rightarrow 0} \frac{R (\Delta R - I)}{\Delta t} \\ &= \lim_{\Delta t \rightarrow 0} \frac{R [\Delta \theta]_{\times}} {\Delta t} \\ &= R[\omega]_{\times} \end{aligned} q˙​R˙​=Δt→0lim​Δtq(t+Δt)−q(t)​=Δt→0lim​Δtq⊗Δq−q​=Δt→0lim​Δtq⊗([1Δθ/2​]−[10​])​=Δt→0lim​Δtq⊗([0Δθ/2​])​=21​q⊗[0ωL​​]=Δt→0lim​ΔtR(t+Δt)−R(t)​=Δt→0lim​ΔtRΔR−R​=Δt→0lim​ΔtR(ΔR−I)​=Δt→0lim​ΔtR[Δθ]×​​=R[ω]×​​ 全局扰动 和局部扰动相对，也就是先通过坐标系的关系变换到其他坐标系下再进行扰动。具体形式为： q~=Δq⊗q\tilde{q} = \Delta q \otimes q q~​=Δq⊗q R~=ΔRR\tilde{R} = \Delta R R R~=ΔRR 由于qA′B=qA′AqABq_{A'B} = q_{A'A}q_{AB}qA′B​=qA′A​qAB​，也就是扰动没有加在局局部下，是加在了坐标系之间的变换这种全局关系中。其时间导数为： q˙=12[ω]Lq=12ω⊗q\dot{q} = \frac{1}{2} [\omega]_L q = \frac{1}{2} \omega \otimes q q˙​=21​[ω]L​q=21​ω⊗q R˙=[ω]×R\dot{R} = [\omega]_{\times} R R˙=[ω]×​R 其中ω\omegaω是全局角速度，也就是要目标坐标系下的角速度，不是当前坐标系下的角速度。 其他的求导 ∂(q⊗a⊗q∗)∂θ=∂(Ra)∂θ=lim⁡∂θ→0R{θ+∂θ}a−Ra∂θ=lim⁡∂θ→0(I+[∂θ]×)Ra−Ra∂θ=−[Ra]×∂(q⊗a⊗q∗)∂q=∂(Ra)∂q=2[qwa+qv×a∣qvTaI+qvaT−aqvT−qw[a]×]\begin{aligned} \frac{\partial (q \otimes a \otimes q^*)}{\partial \theta} &= \frac{\partial (Ra)}{\partial \theta} \\ &= \lim_{\partial \theta \rightarrow 0} \frac{R\{ \theta + \partial \theta \}a - Ra}{\partial \theta} \\ &= \lim_{\partial \theta \rightarrow 0} \frac{(I + [\partial \theta]_{\times})Ra - Ra}{\partial \theta} \\ &= -\left[ Ra \right]_{\times} \\ \\ \frac{\partial (q \otimes a \otimes q^*)}{\partial q} &= \frac{\partial (Ra)}{\partial q} \\ &= 2 \left[ q_w a + q_v \times a | q_v^T a I + q_v a^T - a q_v^T - q_w [a]_{\times} \right] \end{aligned} ∂θ∂(q⊗a⊗q∗)​∂q∂(q⊗a⊗q∗)​​=∂θ∂(Ra)​=∂θ→0lim​∂θR{θ+∂θ}a−Ra​=∂θ→0lim​∂θ(I+[∂θ]×​)Ra−Ra​=−[Ra]×​=∂q∂(Ra)​=2[qw​a+qv​×a∣qvT​aI+qv​aT−aqvT​−qw​[a]×​]​ 旋转矩阵与四元数关系 （不要在意维数的细节问题） q⊗r⊗q∗=Rrq \otimes r \otimes q^* = Rr q⊗r⊗q∗=Rr R4=[q∗]R[q]L=[q]L[q∗]R=[100R] R_4 = [q^*]_R[q]_L = [q]_L[q^*]_R = \begin{bmatrix} 1 & 0 \\ 0 & R \end{bmatrix} R4​=[q∗]R​[q]L​=[q]L​[q∗]R​=[10​0R​] 系统运动（局部） 连续时间 论文里面多是给的连续时间的推导结果 true state： p˙t=vt\dot{p}_t = v_t p˙​t​=vt​ v˙t=Rt(am−abt−an)+gt\dot{v}_t = R_t(a_m - a_{bt} - a_n) + g_t v˙t​=Rt​(am​−abt​−an​)+gt​ q˙t=12qt⊗(ωm−ωbt−ωn)\dot{q}_t = \frac{1}{2} q_t \otimes (\omega_m - \omega_{bt} - \omega_n) q˙​t​=21​qt​⊗(ωm​−ωbt​−ωn​) a˙bt=aw\dot{a}_{bt} = a_w a˙bt​=aw​ ω˙bt=ωw\dot{\omega}_{bt} = \omega _w ω˙bt​=ωw​ g˙t=0\dot{g}_t = 0 g˙​t​=0 其中ama_mam​与ωm\omega_mωm​为测量值，abta_{bt}abt​与ωbt\omega_{bt}ωbt​为true bias，ana_nan​与ωn\omega_nωn​为噪声。 nominal state： p˙=v\dot{p} = v p˙​=v v˙=R(am−ab)+g\dot{v} = R(a_m - a_b) + g v˙=R(am​−ab​)+g q˙=12q⊗(ωm−ωb)\dot{q} = \frac{1}{2} q \otimes (\omega_m - \omega_b) q˙​=21​q⊗(ωm​−ωb​) a˙b=0\dot{a}_b = 0 a˙b​=0 ω˙b=0\dot{\omega}_b = 0 ω˙b​=0 g˙=0\dot{g} = 0 g˙​=0 error state： δp˙=δv\dot{\delta p} = \delta v δp˙​=δv δv˙=−R[am−ab]×δθ−Rδab+δg−Ran\dot{\delta v} = -R[a_m - a_b]_{\times} \delta \theta - R \delta a_b + \delta g - Ra_n δv˙=−R[am​−ab​]×​δθ−Rδab​+δg−Ran​ δθ˙=−[ωm−ωb]×δθ−δωb−ωn\dot{\delta \theta} = -[\omega_m - \omega_b]_{\times}\delta\theta - \delta \omega_b - \omega_n δθ˙=−[ωm​−ωb​]×​δθ−δωb​−ωn​ δab˙=aw\dot{\delta a_b} = a_w δab​˙​=aw​ ωb˙=ωw\dot{\omega_b} = \omega_w ωb​˙​=ωw​ δg˙=0\dot{\delta g} = 0 δg˙​=0 TODO：δv˙\dot{\delta v}δv˙和δθ˙\dot{\delta \theta}δθ˙的推导有时间补上 离散时间 其实和连续时间没差多少，就是把导数变成已经积分好的x←x+x˙Δtx \leftarrow x + \dot{x}\Delta tx←x+x˙Δt。数值积分方法还可以使用其他的，之后的具体形式都需要重新推导，这里是示例。 nominal state： p←p+vΔt+12(R(am−ab)+g)Δt2p \leftarrow p + v\Delta t + \frac{1}{2} (R(a_m - a_b) + g)\Delta t^2 p←p+vΔt+21​(R(am​−ab​)+g)Δt2 v←v+(R(am−ab)+g)Δtv \leftarrow v + (R(a_m - a_b) + g) \Delta t v←v+(R(am​−ab​)+g)Δt q←q⊗q{(ωm−ωb)Δt}q \leftarrow q \otimes q\{ (\omega_m - \omega_b)\Delta t \} q←q⊗q{(ωm​−ωb​)Δt} ab←aba_b \leftarrow a_b ab​←ab​ ωb←ωb\omega_b \leftarrow \omega_b ωb​←ωb​ g←gg \leftarrow g g←g error state： δp←δp+δvΔt\delta p \leftarrow \delta p + \delta v \Delta t δp←δp+δvΔt δv←δv+(−R[am−ab]×δθ−Rδab+δg)Δt+vi\delta v \leftarrow \delta v + (-R[a_m-a_b]_{\times}\delta \theta - R\delta a_b + \delta g) \Delta t + v_i δv←δv+(−R[am​−ab​]×​δθ−Rδab​+δg)Δt+vi​ δθ←RT{(ωm−ωb)Δt}δθ−δωbΔt+θi\delta \theta \leftarrow R^T\{ (\omega_m - \omega_b) \Delta t \}\delta \theta - \delta \omega_b \Delta t + \theta_i δθ←RT{(ωm​−ωb​)Δt}δθ−δωb​Δt+θi​ δab←δab+ai\delta a_b \leftarrow \delta a_b + a_i δab​←δab​+ai​ δωb←δωb+ωi\delta \omega_b \leftarrow \delta \omega_b + \omega_i δωb​←δωb​+ωi​ δg←δg\delta g \leftarrow \delta g δg←δg FFF矩阵可以通过以上内容很容易推导出来，具体形式懒得写了。 error state的期望为000，在预测的过程中就是为了计算协方差矩阵，改变当前期望分布]]></content>
      <tags>
        <tag>math</tag>
        <tag>vio</tag>
        <tag>slam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MSCKF相关问题推导]]></title>
    <url>%2Farchives%2F4392.html</url>
    <content type="text"><![CDATA[MSCKF文章中没有给出的推导和一些疑问。 paper链接 这个逼怕是用的左手系哦！！！！！！ 关于状态向量 这个逼的状态向量里面的四元数是从全局坐标系到IMU坐标系变换的GIq^I_GqGI​q，也就是IMU坐标系中全局坐标系的方向，也就是全局坐标系中IMU坐标系方向的逆 方向的true state为：qˉ=δqˉ⊗qˉ^\bar{q} = \delta \bar{q} \otimes \hat{\bar{q}}qˉ​=δqˉ​⊗qˉ​^​ 导数为:q˙=12ω⊗q\dot{q} = \frac{1}{2} \omega \otimes qq˙​=21​ω⊗q，文章中的Ω(ω)\Omega(\omega)Ω(ω)证明了这个是左手系 Jacobian矩阵 相机状态的Jacobian矩阵计算，单位四元数的逆就是其共轭四元数 error state角度的Jacobian，导数第二步推导使用分配律，RICR^C_IRIC​从IMU坐标变换到相机坐标 qˉ^GC=qˉIC⊗qˉ^GI\hat{\bar{q}}^C_G = \bar{q}^C_I \otimes \hat{\bar{q}}^I_G qˉ​^​GC​=qˉ​IC​⊗qˉ​^​GI​ δqˉGC⊗qˉ^GC=qˉIC⊗δqˉGI⊗qˉ^GI\delta \bar{q}^C_G \otimes \hat{\bar{q}}^C_G = \bar{q}^C_I \otimes \delta \bar{q}^I_G \otimes \hat{\bar{q}}^I_G δqˉ​GC​⊗qˉ​^​GC​=qˉ​IC​⊗δqˉ​GI​⊗qˉ​^​GI​ δqˉGC⊗qˉIC=qˉIC⊗δqˉGI\delta \bar{q}^C_G \otimes \bar{q}^C_I = \bar{q}^C_I \otimes \delta \bar{q}^I_G δqˉ​GC​⊗qˉ​IC​=qˉ​IC​⊗δqˉ​GI​ δqˉGC=qˉIC⊗δqˉGI⊗qˉIC∗\delta \bar{q}^C_G = \bar{q}^C_I \otimes \delta \bar{q}^I_G \otimes {\bar{q}^C_I}^* δqˉ​GC​=qˉ​IC​⊗δqˉ​GI​⊗qˉ​IC​∗ [0,0,0,1]+12[δθC,0]=qˉIC⊗12[δθI,0]⊗qˉIC∗+[0,0,0,1][0, 0, 0, 1] + \frac{1}{2}[\delta \theta ^C, 0] = \bar{q}^C_I \otimes \frac{1}{2}[\delta \theta ^I, 0] \otimes {\bar{q}^C_I}^* + [0, 0, 0, 1] [0,0,0,1]+21​[δθC,0]=qˉ​IC​⊗21​[δθI,0]⊗qˉ​IC​∗+[0,0,0,1] ∂δθC∂δθI=RIC\frac{\partial \delta \theta ^C}{\partial \delta \theta ^I} = R^C_I ∂δθI∂δθC​=RIC​ error state坐标的Jacobian（我觉得文章里面推的不对！） p^CG=p^IG+RGITpCI\hat{p}^G_C = \hat{p}^G_I + {R^I_G}^T p^I_C p^​CG​=p^​IG​+RGI​TpCI​ δpCG+pCG=δpIG+pIG+(δRGIRGI)TpCI猜测文章中是：δRGITRGIT\delta p^G_C + p^G_C = \delta p^G_I + p^G_I + \left( \delta R^I_G R^I_G \right)^T p^I_C \quad \text{猜测文章中是：} {\delta R^I_G}^T {R^I_G}^T δpCG​+pCG​=δpIG​+pIG​+(δRGI​RGI​)TpCI​猜测文章中是：δRGI​TRGI​T δpCG=δpIG+RGITδRGITpCI−RGITpCI\delta p^G_C = \delta p^G_I + {R^I_G}^T {\delta R^I_G}^T p^I_C - {R^I_G}^T p^I_C δpCG​=δpIG​+RGI​TδRGI​TpCI​−RGI​TpCI​ δpCG=δpIG−RGIT[δθI]×pCI由于：δRGI=I+[δθI]×+...\delta p^G_C = \delta p^G_I - {R^I_G}^T \left[\delta \theta ^I \right]_{\times} p^I_C \quad \text{由于：} \delta R^I_G = I + \left[\delta \theta ^I \right]_{\times}+ ... δpCG​=δpIG​−RGI​T[δθI]×​pCI​由于：δRGI​=I+[δθI]×​+... δpCG=δpIG+RGIT[pCI]×δθI\delta p^G_C = \delta p^G_I + {R^I_G}^T \left[ p^I_C \right]_{\times} \delta \theta ^I δpCG​=δpIG​+RGI​T[pCI​]×​δθI ∂δpCG∂δpIG=I\frac{\partial \delta p^G_C}{\partial \delta p^G_I} = I ∂δpIG​∂δpCG​​=I ∂δpCG∂δθI=RGIT[pCI]×\frac{\partial \delta p^G_C}{\partial \delta \theta ^I} = {R^I_G}^T \left[p^I_C \right]_{\times} ∂δθI∂δpCG​​=RGI​T[pCI​]×​ Update 根据残差方程 r=HX~+noiser = H \widetilde{X} + noise r=HX+noise 计算error state，先计算特征点重投影误差和Jacobian矩阵，然后再计算error state 计算特征点坐标 多个相机由feature约束，map: feature -> {camera} 特征点的像素 z=1Z[XY]+n z = \frac{1}{Z} \begin{bmatrix} X \\ Y \end{bmatrix} + n z=Z1​[XY​]+n 特征点在相机坐标系中的坐标有 pf=[XYZ]=R(pf−pC) p_f = \begin{bmatrix} X \\ Y \\ Z\end {bmatrix} = R(p_f - p_C) pf​=⎣⎡​XYZ​⎦⎤​=R(pf​−pC​) 使用最小二乘解得到特征点坐标 先使用首尾两帧三角交汇得到初始解，先通过像素坐标（归一化平面）获得投影方向（各自相机的坐标系）单位长度向量d1d1d1与d2d2d2，即 (u,v,f)→(uf,vf,1)→(u,v,f).normalize()(u,v,f) \rightarrow (\frac{u}{f}, \frac{v}{f}, 1) \rightarrow (u,v,f).normalize() (u,v,f)→(fu​,fv​,1)→(u,v,f).normalize() 然后获取相机C1C_1C1​到C2C_2C2​的旋转矩阵RRR与平移ttt，有 x1d1=t+RTx2d2x_1 d_1 = t + R^T x_2 d_2 x1​d1​=t+RTx2​d2​ t=d1x1−RTd2x2t = d_1 x_1 - R^T d_2 x_2 t=d1​x1​−RTd2​x2​ [d1−RTd2][x1x2]=t \begin{bmatrix} d_1 & - R^T d_2 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = t [d1​​−RTd2​​][x1​x2​​]=t 则x1d1x_1 d_1x1​d1​为特征点在第一个相机的坐标系中的坐标，以此坐标为初始值再利用其他帧数据计算特征点坐标 逆深度参数： (u,v,f)→(u/f,v/f,1/f)(u,v,f) \rightarrow (u/f,v/f,1/f)(u,v,f)→(u/f,v/f,1/f)，逆深度的逆深度是本身 由计算得到的坐标与相机参数得到重投影误差 计算误差Jacobian 重投影误差线性化有 ri(j)≃HXi(j)X~+Hfi(j)GP~fi+ni(j)r^{(j)}_i \simeq H^{(j)}_{X_i} \widetilde{X} + H^{(j)}_{f_i} {}^G\widetilde{P}_{f_i} + n^{(j)}_i ri(j)​≃HXi​(j)​X+Hfi​(j)​GPfi​​+ni(j)​ 其中 HXi(j)=[02×1502×6⋯Ji(j)⌊CiX^fi×⌋−Ji(j)C(GCiqˉ^)⎵Jacobian wrt pose i⋯] H^{(j)}_{X_i} = \begin{bmatrix} 0_{2 \times 15} & 0_{2 \times 6} & \cdots & \underbrace{\begin{matrix} J^{(j)}_i \lfloor {}^{C_i}\hat{X}_{f_i} \times \rfloor & -J^{(j)}_i C({}_G^{C_i}\hat{\bar{q}}) \end{matrix}}_{Jacobian \ wrt \ pose \ i} & \cdots \end{bmatrix} HXi​(j)​=[02×15​​02×6​​⋯​Jacobian wrt pose iJi(j)​⌊Ci​X^fi​​×⌋​−Ji(j)​C(GCi​​qˉ​^​)​​​​⋯​] 与 Hfi(j)=Ji(j)C(GCiqˉ^)H^{(j)}_{f_i} = J^{(j)}_i C({}_G^{C_i}\hat{\bar{q}}) Hfi​(j)​=Ji(j)​C(GCi​​qˉ​^​) 且有 Ji(j)=∇Cip^fjzi(j)=1CiZ^j[10−CiX^jCiZ^j01−CiY^jCiZ^j] J^{(j)}_i = \nabla_{ {C_i}_{\hat{p}_{f_j} } } z^{(j)}_i = \frac{1}{C_i \hat{Z}_j} \begin{bmatrix} 1 & 0 & - \frac{C_i\hat{X}_j}{C_i\hat{Z}_j} \\ 0 & 1 & - \frac{C_i\hat{Y}_j}{C_i\hat{Z}_j} \end{bmatrix} Ji(j)​=∇Ci​p^​fj​​​​zi(j)​=Ci​Z^j​1​⎣⎡​10​01​−Ci​Z^j​Ci​X^j​​−Ci​Z^j​Ci​Y^j​​​⎦⎤​ 将r(j)r^{(j)}r(j)投影到Hf(j)H^{(j)}_fHf(j)​的左零空间，有 ro(j)≃ATHX(j)X~+ATn(j)=H0(j)X~(j)+n0(j)r_o^{(j)} \simeq A^T H^{(j)}_X \widetilde{X} + A^T n^{(j)} = H^{(j)}_0 \widetilde{X}^{(j)} + n^{(j)}_0 ro(j)​≃ATHX(j)​X+ATn(j)=H0(j)​X(j)+n0(j)​ 由于Hf(j)H^{(j)}_fHf(j)​是2Mj×32M_j \times 32Mj​×3满秩矩阵，其左零空间维数为2Mj−32M_j - 32Mj​−3 Update 由于Jacobian矩阵维度很高，因此考虑使用QR分解降低维度，然后使用标准的EKF更新状态和协方差矩阵]]></content>
      <tags>
        <tag>vio</tag>
        <tag>slam</tag>
      </tags>
  </entry>
</search>
